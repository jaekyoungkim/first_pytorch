{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "파이토치 첫걸음.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMszdIQtKu0nOGqRUCTfSLu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaekyoungkim/first_pytorch/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EC%B2%AB%EA%B1%B8%EC%9D%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgG5sBP0YlZU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.검증환경"
      ],
      "metadata": {
        "id": "3uIETj3XYodP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tlNUb8S-dQTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 우분투 16.04 , 파이토치는 0.4부터 윈도우를 지원\n",
        "# 4장~6장 : 무거운 처리를 실행하므로 cuda사용, nvidia gpu필요\n",
        "# cuda : 엔비디아가 제공하는 gpu용의 과학 게산 플랫폼으로 전용 컴파일러나 라이브러리로 구성됨\n",
        "# 본인 pc에 gpu탑재 불가능한경우, aws, azure, gcp등의 클라우드에서 gpu를 탑재한 인스턴스를 사용하는 방법도 있음\n"
      ],
      "metadata": {
        "id": "oENrKZZ9bXdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install nvidia-418\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uYfWwtbb7NP",
        "outputId": "9f927676-0292-4da9-f0b9-6ce8da4f3561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package nvidia-418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo reboot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y5jYqFbctW5",
        "outputId": "ef57847d-dfc8-45a7-e305-09a60650dbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System has not been booted with systemd as init system (PID 1). Can't operate.\n",
            "Failed to talk to init daemon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ng-MV93ccp5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.파이토치의 기본 "
      ],
      "metadata": {
        "id": "hTCEHk8SdRJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치의 패키지 구성\n",
        "# 1. torch : 메인 네임스페이스, 텐서등의 다양한 수학함수가 포함됨\n",
        "# 2. torch.autograd : 자동미분을 위한 함수가 포함, 자동미분의 on/off를 제어하는 콘텍스트 매니저나 미분가능 함수를 정의할때 사용하는 function등이 포함됨\n",
        "# 3. torch.nn : 신경망을 구축하기 위한 다양한 데이터 구조나 레이어등의 정의됨 , conv, lstm, relu, mseloss등 \n",
        "# 4. torch.optim : sgd를 중심으로한 파라미터 최적화 알고리즘이 구현됨\n",
        "# 5. torch.utils.data : sgd의 반복 연산을 실행할때 사용하는 미니 배치용 유틸리티 함수가 포함됨\n",
        "# 6. torch.onnx : onnx포맷으로 모델을 엑스포트 할때 사용, onnx는 서로 다른 딥러닝 프레임 워크 간에 모델을 공유할떄 사용됨\n"
      ],
      "metadata": {
        "id": "310weahrdv1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서\n",
        "# 다차원 배열을 처리하기 위한 데이터 구조\n",
        "# numpy, array와 거의 같은 api를 지님\n",
        "# 텐서는 각 데이터형별로 정의됨 \n",
        "# 32비트의 유동소수점은 torch.FloatTensor\n",
        "# 64비트의 부호있는 정수라면torch.LongTensor \n",
        "# gpu 상의 계산시 torch.cuda.FloattTensor\n"
      ],
      "metadata": {
        "id": "tCKaV7yCe1WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 생성과 변환\n",
        "# 다양한 방법으로 생성 가능\n",
        "import numpy as np \n",
        "import torch \n",
        "t = torch.tensor([[1,2],[3,4.]]) ; t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1LbCsabgr0g",
        "outputId": "6f4a7951-7617-42d2-b478-87c5637a352e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t= torch.tensor([[1,2], [3,4.]], device = \"cuda:0\") ;t "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAQeScoudSim",
        "outputId": "1b8a6572-ffa1-44e6-dcf9-34242fa017b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dtype를 사용해 데이터형을 지정하여 텐서를 만들 수 있음\n",
        "t = torch.tensor([[1,2],[3,4.]], dtype= torch.float64) ;t "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQgiRWJvg-a1",
        "outputId": "1730281c-2a95-4798-df35-f305bb1722c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t= torch.arange(0,10) ; t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-b4aUFVhRKT",
        "outputId": "2e0205c7-c153-4acf-becb-72f14c0fd8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t= torch.zeros(100,10).to(\"cuda:0\") ; t # t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvrp2eKQhZkn",
        "outputId": "b89e9fd5-5d90-4fe9-e11d-53cd5d943f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t= torch.randn(10, 10) ;t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyTc8vyihwkA",
        "outputId": "0d0325b8-4f05-454d-ddfb-e7032f1ee96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4497,  0.6736, -0.7324, -1.0485, -1.3153,  0.2551,  0.8601, -0.6705,\n",
              "          0.8349,  0.0101],\n",
              "        [ 1.6403, -0.2333,  1.1427, -1.0933,  1.8807,  0.8200,  0.4665, -1.0210,\n",
              "         -1.1796, -1.3129],\n",
              "        [ 0.0667,  1.9906,  1.1271,  0.1002, -1.7373,  0.0293, -2.0358, -0.5299,\n",
              "          1.4335,  1.0897],\n",
              "        [ 1.7552,  0.9433,  0.2683,  2.0104,  0.2509, -0.7828, -0.9818,  0.6293,\n",
              "          2.1948, -0.3814],\n",
              "        [ 0.5566, -0.9513,  1.9614,  0.8644,  1.2652, -1.1310,  0.2408, -0.4948,\n",
              "         -1.7695, -0.8663],\n",
              "        [ 0.7239, -1.0591,  2.0326, -0.3334,  0.9148,  0.7331, -0.1892, -0.0998,\n",
              "         -2.2082,  0.7286],\n",
              "        [-0.1878, -0.5154,  0.5148,  0.3801,  1.0625, -1.5046, -0.0590,  0.9657,\n",
              "         -0.6269, -0.3832],\n",
              "        [-0.3617,  0.7213, -0.1901,  0.5730,  0.8108, -0.9505, -1.3907, -0.4488,\n",
              "         -1.9017, -0.0134],\n",
              "        [-1.3951,  1.2199,  0.2149,  0.4532,  0.9360, -0.1669,  0.3504,  1.5673,\n",
              "         -1.6062,  0.2857],\n",
              "        [-0.8615, -1.0350,  0.6175, -2.8511,  1.4963,  1.3705, -1.0067,  0.3301,\n",
              "         -0.0847, -0.4767]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-VhZiZRh6lV",
        "outputId": "edd6862e-b6e2-4e2f-fae2-e4901f1396b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape() # tensor의 사이즈는size로 확인가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "W8YHgXkQiFBF",
        "outputId": "d8cc2be1-b4dc-4c32-e0e7-45451fc330dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f1395bf451d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의변환\n",
        "t= torch.tensor([[1,2], [3,4.]]) ;t \n",
        "x= t.numpy() ;x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ6aA9jniGTL",
        "outputId": "75728e2c-d071-4554-c868-21905e38dc8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu상의 텐서는 to 메서드 사용\n",
        "# cpu텐서로 이동할 필요가 있음\n",
        "t= torch.tensor([[1,2],[3,4]], device= \"cuda:0\") \n",
        "x= t.to(\"cpu\").numpy()  ; x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OXLWbE4kHuI",
        "outputId": "799c01aa-044d-4288-fe6e-7b5ca14a11d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 인덱스 조작\n",
        "# 텐서는 ndarray와 마찬가지로 인덱스 조작을 지원함\n",
        "# A[i,j]의 i,j첨자 인덱스\n",
        "t= torch.tensor([[1,2,3], [4,5,6]]); t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGj6odNrkFpQ",
        "outputId": "002ca36d-0ac1-4b4c-c6cf-a76612f7143a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[0,2] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od3NTHq_km4y",
        "outputId": "c8594045-720c-493e-df53-c9928a5001db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[:, :2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olOf6cOokqHU",
        "outputId": "6da5071e-fa94-4c54-afe7-6a0a36de3c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[:, [1,2]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSgiR4f2krX_",
        "outputId": "df850b48-1bd7-4fc3-97a5-405eee7e9cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 3],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[t>3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfkxj3S7kvov",
        "outputId": "c78ef397-d761-41b2-ca67-96d8c29425f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[0,1] = 100;t  # 0,1요소를 100으로 바꿈 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI8cuBhxkx6l",
        "outputId": "66aec5e7-a5db-4467-c685-ba6b5b01d26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1, 100,   3],\n",
              "        [  4,   5,   6]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[:,1] =200; t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPXClTEhk2tv",
        "outputId": "34642162-1339-4fa9-bf1b-248ce8eb45c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1, 200,   3],\n",
              "        [  4, 200,   6]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[t>10] = 20; t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxtQsw8Dk4yH",
        "outputId": "912ac996-add6-4db2-d681-c455f1d51be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 20,  3],\n",
              "        [ 4, 20,  6]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mask 배열 [f,f,t]등의 각 요소가 t or f"
      ],
      "metadata": {
        "id": "yeAUIcsKk8NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 연산\n",
        "# 텐서는 사칙 연산이나 수학함수, 선형대수 계산등이 가능함-> ndarray대신에 사용할 수 있음\n",
        "# 행렬곱이나 특이값분해등의 선형대수 계산은 gpu를 사용할 수 있음\n",
        "# 대규모 데이터를 처리할떄는 numpy scipy보다 훨씬 빠름\n",
        "# 사칙연산은 텐서간이나 텐서와 파이썬의 스칼라값에만 가능함\n",
        "# 텐서와 ndarray간 연산은 지원하지 않음\n",
        "# 텐서간에도 동일한 형이어야 함\n",
        "# floattensor와 doubletensor연산시에는 오류가 발생\n",
        "# 사칙연산은ndarray처럼 브로드캐스트가 적용돼서 두개의 서로 다른 차원의 벡터와 스칼라 또는 행렬과 벡터 간의 연산시 결괏값의 차원은 두 차원 중 큰차원을 따르는 차원보간이 이뤄짐\n"
      ],
      "metadata": {
        "id": "QIz35WRLlB5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v= torch.tensor([1,2,3])\n",
        "w= torch.tensor([0,10,20]) \n",
        "m= torch.tensor([[0,1,2], [100,200,300]]) "
      ],
      "metadata": {
        "id": "-XiVa0EPnP5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v2= v+10; v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWAHI03inZwO",
        "outputId": "4b139a49-533d-4b1b-a5e9-25c7322a9ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2 = v**2;v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD9AjTFRna5L",
        "outputId": "c93b274c-c07f-4f0b-eb29-3c368a6c30b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z= v-w;z\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnm-8G2-ncos",
        "outputId": "f664abc8-3c25-4f54-bbd3-3f212bce57e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1,  -8, -17])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u = 2*v-w /10 + 6; u"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkWvps1zngE3",
        "outputId": "1c103628-9e8d-41b8-a71b-c5d90676ed42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8.,  9., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = m * 2.0;m2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7rogDZAnklW",
        "outputId": "05827b8a-a41a-48f9-a563-18412c9d059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   2.,   4.],\n",
              "        [200., 400., 600.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m3 = m+v; m3 #브로드캐스트가 적용됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o6eajm0noxo",
        "outputId": "4acf3758-ae32-4a94-faa3-e13ba478b0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1,   3,   5],\n",
              "        [101, 202, 303]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4 = m + m; m4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukTJzMTIn4tD",
        "outputId": "ca222264-94a6-412b-e05f-d57f6de9d4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   2,   4],\n",
              "        [200, 400, 600]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 수학함수\n",
        "X = torch.randn(100,10) \n",
        "y= X*2+ torch.abs(X) ;y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we761FhQn6Hq",
        "outputId": "059f51c8-fbea-45ab-da13-800eaa23d768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.9221e-01, -1.2603e+00,  6.7976e+00, -1.3200e+00, -7.4547e-01,\n",
              "          5.2396e+00, -8.2165e-01, -1.1094e+00,  8.1720e+00,  8.6783e-01],\n",
              "        [-1.4690e+00, -8.8312e-01,  3.1006e+00,  1.5288e+00,  1.3724e+00,\n",
              "          3.2097e+00,  3.7131e+00,  2.2249e+00,  1.6374e+00,  1.3883e+00],\n",
              "        [ 2.2505e+00, -8.9221e-01,  2.6224e+00,  9.5893e-01, -1.1626e+00,\n",
              "         -4.1802e-02,  4.6794e+00, -7.1971e-01, -8.8695e-01,  2.3247e+00],\n",
              "        [ 4.0958e+00, -5.5391e-01, -1.1528e+00, -4.1156e-01, -8.8949e-01,\n",
              "         -4.4894e-01,  5.9509e-01,  1.6687e+00,  9.6610e-01, -6.6284e-01],\n",
              "        [-3.0419e+00, -2.8883e-01, -1.1320e+00,  1.2187e+00,  2.5119e+00,\n",
              "          4.0545e+00,  3.6259e-01, -5.3140e-01, -2.2119e+00, -4.5708e-02],\n",
              "        [-6.1885e-01,  7.3800e+00, -1.3499e+00,  5.0148e+00,  1.6502e+00,\n",
              "          2.7433e+00, -4.6232e-01,  1.3886e+00, -1.7076e-01,  1.5590e+00],\n",
              "        [-4.2166e-01,  1.9242e+00,  6.3140e-01, -1.3374e+00, -1.2501e+00,\n",
              "          2.6483e+00,  8.1376e-01,  5.3658e+00,  2.2127e+00, -3.2418e-01],\n",
              "        [-3.4505e-01, -7.6941e-01, -8.1090e-01,  9.3732e-01, -4.4468e-01,\n",
              "          2.2504e+00,  3.0795e+00,  6.2578e+00, -7.1177e-01,  3.9668e+00],\n",
              "        [ 2.9801e+00,  2.0680e+00, -1.1641e-02,  2.5484e+00, -4.7498e-01,\n",
              "          7.5471e+00, -6.3300e-01,  6.3182e-01, -1.5930e-01, -3.3553e-01],\n",
              "        [-1.4423e+00,  4.1633e-01, -5.0637e-01, -3.5048e-01,  2.5886e+00,\n",
              "         -1.4472e+00,  2.9255e+00,  2.0752e+00,  1.8731e-01, -7.7418e-01],\n",
              "        [ 5.9119e+00,  8.0266e-01, -9.2795e-01,  1.4155e+00, -1.8075e+00,\n",
              "          5.6910e+00,  1.6926e+00, -1.1525e+00,  1.5968e+00,  2.0285e-01],\n",
              "        [ 1.9367e+00,  2.3860e+00, -5.6073e-01, -3.0767e-01, -7.6464e-01,\n",
              "          6.8885e+00, -1.6964e-01, -1.1764e+00, -2.3841e+00,  3.9782e+00],\n",
              "        [ 1.0398e+00, -6.4234e-01,  1.3393e+00,  4.1344e+00, -6.0344e-02,\n",
              "         -4.1453e-01, -2.7712e-01,  3.2958e+00,  2.1288e+00, -1.1417e+00],\n",
              "        [ 4.1851e+00,  2.3962e+00,  1.0308e+00,  1.8242e+00,  7.8598e+00,\n",
              "         -6.3079e-01,  2.2770e+00,  4.3978e+00,  8.4221e-01, -3.2456e+00],\n",
              "        [-3.4869e-01, -6.1677e-01, -3.5943e-01,  1.8817e+00, -1.6507e+00,\n",
              "          3.6792e+00,  5.5790e+00,  3.1488e+00,  2.3747e+00, -4.4468e-01],\n",
              "        [-9.8899e-02, -4.5804e-01, -3.8235e-01, -1.4196e+00,  2.0586e+00,\n",
              "          3.0252e+00,  4.1529e-01,  1.5853e+00, -1.2248e+00,  3.3273e+00],\n",
              "        [-2.0408e-02,  4.2168e+00,  3.8913e-01,  3.4770e+00, -6.6298e-01,\n",
              "         -3.2641e-01,  8.6124e-03,  1.7054e+00, -6.8397e-01, -5.9520e-01],\n",
              "        [-8.0012e-02, -7.4422e-01,  4.2130e+00, -6.4018e-02,  1.4421e+00,\n",
              "          2.4051e-01, -1.2280e-01,  6.4326e+00,  2.2887e-01,  1.6086e+00],\n",
              "        [-1.1749e+00, -9.7923e-02, -3.3312e-01, -1.0219e+00, -1.0056e+00,\n",
              "         -3.4713e-01, -1.9062e+00, -2.1738e-01,  7.1315e-01,  1.9993e+00],\n",
              "        [-1.4232e+00, -4.9248e-02, -1.1747e+00, -1.0221e+00, -8.7684e-01,\n",
              "         -9.6060e-01, -1.9678e-01, -9.0239e-01,  1.1302e+00, -4.2031e-01],\n",
              "        [-1.2091e+00, -1.7381e+00, -1.8618e+00, -1.8240e+00, -1.7834e-01,\n",
              "          3.8058e+00, -1.7735e-01, -6.4736e-01, -1.0521e+00, -5.7802e-01],\n",
              "        [-4.4780e-01, -4.7396e-01,  5.3433e+00,  6.9060e-01,  1.9954e+00,\n",
              "         -4.2917e-01, -4.3702e-01,  2.0610e-01, -5.9612e-01, -3.1468e-01],\n",
              "        [ 6.4161e+00,  2.8181e+00, -1.5460e+00, -1.9394e-01,  1.1253e+00,\n",
              "         -9.1010e-01,  7.5466e-01,  9.2022e-01,  1.8573e+00, -7.2698e-01],\n",
              "        [-5.1439e-01, -7.8219e-01,  2.3961e+00, -5.3736e-01, -6.6621e-01,\n",
              "          8.6751e-01,  3.9136e+00, -6.5785e-01, -1.1009e+00,  7.7688e-01],\n",
              "        [-1.1430e+00, -5.8480e-02, -1.1314e-02, -5.6074e-01,  4.9521e+00,\n",
              "         -4.0958e-01,  3.1741e+00,  2.2349e+00,  1.4027e-01,  5.2720e+00],\n",
              "        [ 9.2340e-01, -1.9110e-01, -1.1043e-01,  2.9059e-01, -5.5236e-01,\n",
              "          5.8940e-01, -7.8614e-01, -7.7350e-02, -3.7909e-01, -4.5910e-01],\n",
              "        [ 5.0670e+00, -1.3697e+00, -7.9040e-01,  5.4869e-01,  1.1415e+00,\n",
              "         -9.2963e-01, -1.4458e+00,  2.5874e+00, -3.7045e-01,  2.0014e+00],\n",
              "        [ 4.1367e+00,  2.9832e+00,  1.4193e-01,  4.1325e+00, -1.1446e+00,\n",
              "          5.4558e-01,  4.3990e+00,  1.1668e-01,  5.9030e+00, -3.3856e-01],\n",
              "        [ 1.3463e+00, -3.4731e-01, -8.0813e-01,  3.0736e+00, -1.3113e+00,\n",
              "          2.4094e+00, -1.9668e-01,  6.3507e-01, -1.4205e+00,  4.9696e-01],\n",
              "        [ 3.8520e-01,  1.3227e+00,  4.3641e+00, -2.9986e-01, -3.9930e-01,\n",
              "          1.5739e-02,  4.1220e+00,  1.3000e+00, -1.3746e+00,  2.9394e+00],\n",
              "        [ 2.0967e+00, -2.6655e-01, -8.3884e-01, -6.0901e-03, -3.8100e-02,\n",
              "         -1.0717e+00, -7.1653e-01,  5.8784e-01,  2.9745e+00, -3.9689e-01],\n",
              "        [ 1.8061e+00, -1.1388e+00,  5.5668e-01,  2.6843e+00, -3.3194e-01,\n",
              "         -1.3636e-01,  1.3250e+00,  5.7373e+00, -7.5667e-01,  3.3345e+00],\n",
              "        [ 2.3639e+00, -7.4938e-01,  2.4278e+00,  4.4116e+00,  3.5874e+00,\n",
              "         -3.5212e-01,  5.4440e+00,  2.4294e+00,  4.5284e+00, -1.3494e+00],\n",
              "        [ 5.1630e-01, -5.1528e-01, -9.3079e-01, -1.5704e+00,  2.0565e+00,\n",
              "          2.3611e-01,  1.5989e+00,  1.7546e+00, -5.4124e-01, -2.2904e-01],\n",
              "        [-1.3275e+00,  2.8174e+00,  5.5504e-01,  4.1387e-01, -7.7757e-01,\n",
              "         -2.7947e-01,  2.4617e+00, -2.2303e+00,  6.2163e-01,  8.4843e+00],\n",
              "        [ 5.2969e-01, -2.2835e-01, -3.8563e-01, -1.2458e+00, -7.7619e-01,\n",
              "         -3.1750e-01, -8.5702e-01,  2.7184e+00, -1.9897e-01,  1.8002e+00],\n",
              "        [-2.0626e-01, -8.1994e-01,  1.4789e+00,  2.4024e+00, -3.5558e-01,\n",
              "         -1.5788e+00,  4.7452e+00, -3.5348e-01,  3.7646e+00, -3.7485e-01],\n",
              "        [ 3.1794e+00, -6.1410e-01, -4.1101e-02,  1.9302e+00, -1.4149e+00,\n",
              "         -6.7266e-01,  2.0487e+00, -3.1527e-01, -6.1040e-01, -2.5215e-01],\n",
              "        [-1.1901e+00,  2.0630e+00,  3.7691e+00,  2.5285e+00, -1.1302e+00,\n",
              "         -4.5605e-01,  1.6231e+00,  1.6980e-01,  3.8302e+00,  2.0865e+00],\n",
              "        [ 2.5762e+00, -1.9412e+00, -2.6030e+00, -1.4655e+00, -5.0150e-01,\n",
              "          2.7200e+00,  6.1913e+00, -6.1012e-01,  2.8385e+00,  3.7097e+00],\n",
              "        [ 2.5734e+00,  2.5040e+00,  5.3311e-02, -3.5766e-01,  2.5701e+00,\n",
              "         -1.1649e+00,  1.1902e+00,  1.8929e+00, -7.2144e-01,  4.7679e+00],\n",
              "        [ 8.8676e-01, -1.2876e+00, -1.9890e+00,  3.7770e+00, -8.4439e-01,\n",
              "         -5.0641e-01, -5.0476e-01, -5.9269e-01, -1.6831e-01, -1.5760e-02],\n",
              "        [-7.7301e-01,  2.6692e+00, -1.5885e-02, -2.1805e+00, -1.4843e+00,\n",
              "          1.6885e+00,  3.0897e+00, -3.1268e-02,  2.3791e+00, -1.1506e-01],\n",
              "        [ 1.3614e+00,  5.3426e+00,  1.4121e+00,  2.1806e-01,  2.8024e+00,\n",
              "          2.4711e+00, -6.6815e-01, -4.7190e-01, -1.1949e+00,  6.3240e-01],\n",
              "        [-1.2908e-01, -1.2181e+00, -2.6927e-01,  1.8761e+00,  4.0746e-01,\n",
              "          1.5357e+00,  1.9944e+00,  1.5866e+00, -8.2807e-01, -1.7726e+00],\n",
              "        [-7.6894e-01, -1.2381e+00,  2.8140e+00, -1.4616e+00,  6.7836e-01,\n",
              "         -3.7905e-01,  2.0491e+00, -2.9792e-01, -1.2635e+00, -3.9569e-01],\n",
              "        [ 4.4727e+00, -2.4131e-01,  2.7339e+00, -7.2144e-01,  5.3550e-01,\n",
              "         -4.4615e-02, -3.6812e-01, -1.6178e-01,  3.0729e+00,  1.3279e+00],\n",
              "        [ 5.0441e+00,  7.0771e+00,  1.5219e+00, -1.3349e+00, -1.3051e+00,\n",
              "          1.6415e+00, -1.7794e+00, -1.0673e+00, -6.9934e-02,  2.5177e+00],\n",
              "        [-9.3432e-01, -9.0582e-01,  7.2252e+00, -1.5569e-01, -5.4895e-01,\n",
              "          1.3798e+00,  4.9038e+00,  6.7974e+00, -4.7063e-01,  1.5984e+00],\n",
              "        [-7.8894e-01, -1.3162e+00, -4.0965e-02, -7.4673e-01,  4.5223e+00,\n",
              "          2.1743e-01, -9.8696e-01, -2.0600e-01,  5.4967e+00,  5.8961e+00],\n",
              "        [-1.1860e-01,  1.1997e-01,  3.1516e+00, -6.8702e-01,  1.6058e+00,\n",
              "          1.2947e+00,  5.1055e+00,  1.7204e+00, -2.4842e-01, -3.7829e-01],\n",
              "        [-6.4378e-01,  4.4100e+00, -1.7928e+00,  1.7494e-01,  1.9999e+00,\n",
              "          2.0842e+00, -1.9280e-01, -1.1497e+00,  4.0752e-01,  7.0628e-01],\n",
              "        [ 2.9486e-01, -1.0093e+00,  1.5996e+00,  3.4724e+00,  1.4024e+00,\n",
              "         -9.7574e-01, -2.1642e-02, -5.6150e-01, -1.8512e+00, -7.1112e-01],\n",
              "        [-1.8803e+00, -3.0199e-02,  2.4522e+00,  3.5506e+00,  1.7243e+00,\n",
              "          3.9686e+00,  1.0600e+00,  4.1171e+00,  1.9618e+00,  3.3625e-02],\n",
              "        [ 7.8733e-01,  3.6358e+00,  2.9217e-01, -4.1474e-01,  1.2162e+00,\n",
              "          3.0367e+00, -8.0581e-01, -1.7996e+00, -6.6468e-01, -6.0726e-01],\n",
              "        [ 1.2661e+00,  1.6020e+00,  3.2334e+00, -9.6473e-01,  5.3192e-01,\n",
              "         -1.8558e+00, -1.0264e+00, -1.6298e-01,  6.7645e+00,  2.1984e+00],\n",
              "        [-8.5231e-01,  4.1463e+00,  2.7684e+00,  1.3312e+00, -5.3353e-01,\n",
              "          3.7523e+00, -8.0151e-01, -1.5882e-01,  6.0331e-02,  6.1989e+00],\n",
              "        [-2.1894e-01,  2.3114e+00,  2.4494e+00,  4.0996e+00, -3.0114e-01,\n",
              "         -2.1064e-01,  2.3508e+00,  3.7263e+00,  2.7868e+00, -8.2070e-01],\n",
              "        [ 3.4568e+00, -4.6595e-01, -8.2915e-01,  4.8300e-01, -5.2237e-01,\n",
              "         -2.8546e-01,  3.9426e-01,  6.2567e-01,  2.1822e+00, -6.6230e-01],\n",
              "        [-9.9606e-02, -7.7490e-01,  1.1950e+00, -1.5910e-01, -2.3641e+00,\n",
              "         -1.0288e+00,  9.6147e-01,  9.3364e-01,  1.1197e+00,  7.6102e-01],\n",
              "        [ 4.7338e-02,  8.8955e-01, -1.5360e+00, -1.1779e+00, -5.2476e-01,\n",
              "         -9.8061e-02,  1.2544e+00, -4.6435e-01,  3.5407e+00, -6.7566e-02],\n",
              "        [ 2.3502e+00, -6.2787e-01, -5.2149e-01, -1.7140e+00, -1.3060e+00,\n",
              "          7.2505e-01, -1.1460e+00,  2.0654e-01, -2.1739e+00, -6.2575e-02],\n",
              "        [-1.8276e+00, -5.2788e-02,  3.0756e+00,  2.0480e+00, -1.6554e+00,\n",
              "         -1.3603e+00,  2.2979e+00,  4.4684e+00,  4.5898e-01,  1.1602e+00],\n",
              "        [-9.0243e-02, -8.4609e-03,  5.4736e+00, -1.2080e+00, -7.2132e-02,\n",
              "         -1.3434e-01, -1.3380e+00, -9.5775e-01,  3.7152e+00,  1.5597e+00],\n",
              "        [ 7.7471e+00,  8.6056e-01,  3.7551e+00, -3.4053e-01, -1.8794e+00,\n",
              "          2.8325e+00, -1.0013e+00, -2.1789e-01, -1.0778e+00,  9.3977e-01],\n",
              "        [ 1.2882e+00, -7.8442e-01,  2.5842e+00,  4.2734e+00, -3.6208e-01,\n",
              "          2.6512e+00,  9.8376e-01,  6.4296e+00,  3.7735e-01, -8.6111e-01],\n",
              "        [-1.6645e-01, -1.8148e+00, -5.4093e-01, -1.9247e+00,  4.2870e+00,\n",
              "          7.8561e-01,  1.6728e+00, -4.5722e-01, -7.4334e-01, -3.1846e-01],\n",
              "        [ 2.8238e+00, -1.8636e-02, -1.3401e+00, -3.9094e-01, -6.6928e-02,\n",
              "          3.2692e+00, -1.8071e-01, -4.2635e-01, -6.0564e-01, -1.0817e+00],\n",
              "        [-2.0579e+00,  4.7203e+00,  1.6445e+00, -9.2866e-02,  2.8968e+00,\n",
              "         -1.3733e+00, -2.3247e-02,  3.0838e+00, -3.9140e-02, -4.1130e-01],\n",
              "        [ 2.9535e+00,  3.4508e+00, -6.8332e-01,  1.0504e+00,  9.4543e-01,\n",
              "         -1.1048e+00,  2.1688e+00,  2.6140e+00,  2.7563e-01, -1.8117e+00],\n",
              "        [-6.3128e-01, -9.7247e-01,  3.3667e+00, -1.1404e+00,  1.4619e+00,\n",
              "         -3.8156e-01, -1.8077e-02, -2.2777e+00, -1.9907e+00, -6.5499e-01],\n",
              "        [ 7.1490e-01,  5.2430e+00,  3.9881e+00,  1.6340e+00,  4.5429e-01,\n",
              "          2.9484e+00, -5.6427e-02,  8.9909e+00,  6.4340e+00,  1.5485e+00],\n",
              "        [-2.5963e+00, -4.7406e-02,  2.5123e+00, -1.5611e+00, -1.0381e+00,\n",
              "         -1.3829e+00,  9.9189e-01, -1.9270e-01, -1.1527e+00, -1.6845e-01],\n",
              "        [-3.0520e+00,  7.3683e-01, -1.2656e+00,  5.0294e-01, -3.3591e-01,\n",
              "          2.7780e+00,  3.7644e+00, -3.3578e-01,  1.5249e+00, -2.6047e-01],\n",
              "        [-1.1467e+00,  4.5672e-01, -7.0756e-01,  3.8924e+00, -4.1499e-01,\n",
              "         -1.0597e-01, -5.2634e-01, -2.0116e-01, -7.4153e-01,  3.8406e-01],\n",
              "        [ 1.3869e+00,  3.8392e+00,  5.0393e-01,  1.1493e+00,  1.5787e+00,\n",
              "          1.3488e+00,  1.6120e+00,  4.8380e-01, -9.7653e-02, -7.7480e-01],\n",
              "        [ 3.1281e+00,  3.2967e+00,  4.1608e-01, -1.4562e-01, -2.5765e-01,\n",
              "          2.5619e+00, -3.9682e-01,  7.7871e-01,  6.4676e-01,  1.1656e+00],\n",
              "        [ 7.2289e-01, -9.0204e-02,  7.2129e+00, -1.1794e+00, -8.2112e-01,\n",
              "         -1.6472e+00,  1.7840e+00, -9.7352e-01,  2.4350e-01,  5.2523e+00],\n",
              "        [ 3.8691e+00, -1.4750e-01, -1.7469e+00, -1.3472e+00, -9.7389e-02,\n",
              "          1.3316e+00, -9.5016e-01, -1.5020e-01, -1.0799e+00,  2.2261e+00],\n",
              "        [ 1.3287e+00, -2.5037e+00, -1.1876e-01,  1.6067e+00,  1.8753e-01,\n",
              "          5.8980e+00, -6.2716e-01,  5.1931e+00,  5.5552e+00,  5.0458e-03],\n",
              "        [ 3.3292e+00,  1.5431e+00,  3.0627e+00,  2.8345e+00, -9.7558e-01,\n",
              "          3.6156e+00, -1.2249e+00, -1.7371e+00,  1.1340e+00, -1.4339e+00],\n",
              "        [-1.1934e+00,  5.8775e+00,  3.8374e+00, -6.1338e-01,  3.0551e+00,\n",
              "          9.3872e-02,  3.1016e+00,  2.8213e-01, -1.2915e-02, -2.3155e+00],\n",
              "        [ 4.5204e-01, -1.3148e+00,  9.5198e-01, -3.0843e-01,  1.8526e+00,\n",
              "         -5.0061e-01,  2.0721e+00, -2.4101e-01,  6.1612e+00, -5.1856e-01],\n",
              "        [ 1.6843e+00,  3.9619e-01,  1.6004e+00,  3.0513e+00, -8.9842e-01,\n",
              "         -9.0658e-01, -1.2273e+00,  3.2318e+00,  2.3331e+00, -7.0104e-01],\n",
              "        [-6.5558e-01, -3.3008e-01, -2.2302e-01,  1.1029e+00,  3.5766e+00,\n",
              "          1.0230e+00,  1.0846e+00,  5.2950e+00, -3.9958e-02, -1.9247e-01],\n",
              "        [-1.5930e+00,  1.0961e+00,  1.1517e+00, -8.6908e-01, -3.1334e-01,\n",
              "         -5.7629e-01,  6.8484e+00,  7.0572e-01, -6.4910e-01,  1.6344e+00],\n",
              "        [-2.6614e-01, -9.4172e-01,  1.2432e+00,  8.5311e-01, -1.8102e+00,\n",
              "         -1.9746e-01, -1.0776e+00,  1.4107e+00,  2.5678e+00, -7.8839e-01],\n",
              "        [-1.0056e+00,  1.8518e+00,  2.9850e+00, -1.5037e+00,  1.7057e+00,\n",
              "          2.2180e+00, -1.2576e-01, -4.0394e-01,  5.1861e+00, -3.9173e-01],\n",
              "        [-1.4172e-01, -6.0933e-01, -9.9923e-01, -6.0126e-01,  1.2887e+00,\n",
              "          2.6357e+00,  2.1158e+00, -1.1561e+00, -1.3487e+00,  2.9612e+00],\n",
              "        [ 2.2866e+00, -2.0440e+00, -1.7524e+00, -1.1972e+00,  4.7793e-01,\n",
              "          3.3740e+00,  2.4646e+00, -1.7823e-01, -3.8512e-02,  1.9462e+00],\n",
              "        [-1.1480e+00,  4.4881e+00, -1.4125e-01, -5.1232e-01, -7.2254e-01,\n",
              "         -8.9145e-02, -7.2142e-01,  1.9059e+00,  5.5420e+00,  1.9474e-01],\n",
              "        [ 1.6120e+00,  2.1205e+00, -9.5809e-02,  1.0161e-01, -3.0717e-01,\n",
              "          2.9927e+00, -5.4146e-02,  3.0978e+00, -1.1168e-01, -1.0233e+00],\n",
              "        [-6.8281e-02, -2.6997e-02, -3.0167e-01, -7.7856e-01, -2.9845e-02,\n",
              "         -1.8691e-01, -6.8356e-01, -2.9145e-01,  2.0502e+00, -4.1842e-01],\n",
              "        [-1.2099e+00,  1.3133e+00,  1.2385e+00, -1.6026e+00,  1.8878e+00,\n",
              "          3.3896e+00, -7.0979e-02, -4.2096e-02,  3.2646e+00, -9.7494e-01],\n",
              "        [-5.2552e-01,  2.4778e-01, -1.3674e+00,  3.1926e+00,  1.6084e+00,\n",
              "          1.8503e+00,  4.5250e+00,  5.9719e+00,  1.6070e+00, -9.0720e-01],\n",
              "        [ 2.1757e+00, -9.9597e-01, -7.0688e-01,  6.0027e+00,  5.7512e-01,\n",
              "         -1.8075e+00,  1.3205e+00,  2.8769e+00, -8.4462e-01, -9.3960e-01],\n",
              "        [-1.0807e+00,  1.2861e+00,  2.9072e+00, -1.4904e+00,  1.9543e+00,\n",
              "         -1.7900e+00,  5.1513e-01,  5.1635e+00,  1.5228e+00, -5.5287e-01],\n",
              "        [ 2.2902e+00,  1.2424e+00,  2.0796e-01,  2.1039e+00,  2.1934e+00,\n",
              "          5.9707e-01, -1.1229e-01,  4.7954e+00, -1.0496e+00, -1.7336e-01],\n",
              "        [ 2.8935e+00, -8.2810e-02,  4.0100e+00, -1.0134e+00,  2.0093e+00,\n",
              "         -7.0719e-01, -1.2343e-01,  6.8692e+00, -4.8544e-01, -3.4071e-01],\n",
              "        [ 2.3529e+00,  2.6704e+00,  3.4645e+00, -3.8937e-01, -7.6553e-01,\n",
              "         -5.2082e-01, -7.2380e-01, -4.8874e-01,  1.5491e+00, -7.2590e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균치 구하기 \n",
        "m = torch.mean(X) ; m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ayS_T2soG6s",
        "outputId": "cf525077-afdc-4060-fc86-723f5d705b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0239)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = X.mean(); m # 함수가 아닌  메서드 형태로 실행가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tpMKjX0oK9L",
        "outputId": "b0d03a20-b327-4f7b-adc0-0e41e9f618e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0239)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 집계결과는 0차원 텐서로 item메서드를 사용해서 값 추출 가능"
      ],
      "metadata": {
        "id": "A-bMEmTsoSbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor([[1,2], [3,4.]])  # 2x2\n",
        "x2 = torch.tensor([[10,20,30], [40,50,60]]) # 2x3\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXO-E3d1ofay",
        "outputId": "679805c6-73fd-4351-909d-4b3426d7c3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10, 20, 30],\n",
              "        [40, 50, 60]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2x2 를  4x1로 보여준다\n",
        "x1.view(4,1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JblNAqZWoojs",
        "outputId": "12331190-beec-41c7-9f82-759245b026ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2.t()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eLMrNLLotbl",
        "outputId": "f4379a47-2ff2-4c94-b84d-0cdd0feac757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10, 40],\n",
              "        [20, 50],\n",
              "        [30, 60]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dim=1 로 결합하면 2x5의 텐서를 만들수있음\n",
        "torch.cat([x1,x2], dim=1) # 2x5\n",
        "\n",
        "# 2x2 concat 2x3 \n",
        "# 두번째 차원으로 합치기 2x(2+3) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA0Bl0SFou0j",
        "outputId": "60650f94-c9d9-45f4-a855-d2a1e0ce4ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  2., 10., 20., 30.],\n",
              "        [ 3.,  4., 40., 50., 60.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([x1,x2], dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "UXvjRyugo9uI",
        "outputId": "b7d2f511-45d6-4e3f-e641-d341765a1237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-444c6e1de9b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 2 but got size 3 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HWC를 CHW로 변환\n",
        "hwc_img_data = torch.rand(100,64,32,3) \n",
        "chw_img_data = hwc_img_data.transpose(1,2).transpose(1,3) ; chw_img_data.size()\n",
        "# (100,64,32,3)  - > [100,32,64,3] -> [100,32,64,3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9mvxhoTpAxl",
        "outputId": "c2bd28e2-1e08-402e-f166-9c4faff99e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 3, 64, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형대수의 연산자\n",
        "# dot : 벡터내적\n",
        "# mv : 행렬과 벡터의 곱\n",
        "# mm : 행렬과 행렬의 곱\n",
        "# matmul : 인수의 종류에 따라 자동으로 dot, mv, mm을 선택해서 실행\n",
        "# gesv : LU분해를 사용한 연릭방정식의 해\n",
        "# eig.symeig : 고유값 분해, symeig는 대칭 행렬보다 효율이 좋은 알고리즘\n",
        "# svd : 특이값 분해\n"
      ],
      "metadata": {
        "id": "uaTJ4k2epp1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "m = torch.randn(100,10) \n",
        "v = torch.randn(10) \n",
        "d = torch.dot(v,v) ;d #벡터 내적"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owk16dGsuVyy",
        "outputId": "33277c40-5d6b-454c-c624-76a052578c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13.9528)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2 = torch.mv(m,v) ; v2 # 100차원 행렬과 벡터의 곱"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz5CS_iL402j",
        "outputId": "82e0edb8-aaa2-4777-8e68-c15228303b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7196, -5.6262, -2.7636,  2.5451, -1.4247,  2.6885, -0.1412, -4.4001,\n",
              "        -0.2208,  0.9396, -5.1157,  1.1583,  1.5345, -0.5466, -0.1194,  5.1450,\n",
              "        -7.2692, -1.2521,  4.6835,  0.6710, -6.1006, -4.7107, -3.4808, -6.9523,\n",
              "         2.2625,  0.0338,  2.8336, -3.9873,  3.0829, -2.9793, -1.5277, -1.5002,\n",
              "        -1.3905, -0.2505, -2.3691,  2.7653, -2.7163,  4.1164,  0.1837, -4.0685,\n",
              "        -0.8255, -5.5428,  2.6199, -4.6069,  5.6038, -2.3431,  0.4932,  0.6682,\n",
              "         6.3418, -2.6432, -4.3154, -5.3974, -7.1547,  0.7274, -0.1376, -1.9873,\n",
              "         2.4482, -9.9913, -6.8943,  1.3872,  2.0703, -0.3023,  1.3168,  2.7784,\n",
              "         0.6082, -1.4031, -0.8793,  3.1850, -2.5085, -0.1537,  3.8219,  0.0511,\n",
              "         1.7745, -0.3348,  0.3608,  3.3026, -6.4903,  0.8190,  4.8867,  3.3216,\n",
              "        -4.5565,  0.4270,  4.5038,  2.9676,  4.6522, 10.6578,  1.7539, -4.2254,\n",
              "        -2.0053,  0.9829,  1.3450,  3.2908,  1.8015,  0.7654,  0.1382,  5.1534,\n",
              "         5.8138,  2.5127, -1.3300,  0.8284])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = torch.mm(m.t(), m) ;m2 # 10x10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLVTT_cK5jFn",
        "outputId": "90c8394d-4d46-4c1d-ead2-b4af95b29b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[118.4707,   4.1114,   6.9955,  35.7579,  13.4251,   6.8365,  -3.6286,\n",
              "         -11.7381, -14.6536,  25.5066],\n",
              "        [  4.1114,  84.3602,  -2.7952,  -9.0201,  15.5138,   7.0633, -13.5769,\n",
              "           5.0436,  -0.3266,   8.5041],\n",
              "        [  6.9955,  -2.7952,  93.2776, -10.0067,  21.9992,   5.2277,  11.8536,\n",
              "          -2.2523, -12.4800,  -7.2879],\n",
              "        [ 35.7579,  -9.0201, -10.0067, 126.0756,  -0.8590, -13.7646,  12.8496,\n",
              "          -9.4292,  -1.2362,   2.1052],\n",
              "        [ 13.4251,  15.5138,  21.9992,  -0.8590,  85.0130,  -1.7628,  -6.1835,\n",
              "           3.1972,  -7.0912,  10.8148],\n",
              "        [  6.8365,   7.0633,   5.2277, -13.7646,  -1.7628,  87.7354,  -7.4755,\n",
              "          -5.0118,  14.7625,   9.2338],\n",
              "        [ -3.6286, -13.5769,  11.8536,  12.8496,  -6.1835,  -7.4755,  96.7050,\n",
              "         -15.3422,  16.4220,  -6.2517],\n",
              "        [-11.7381,   5.0436,  -2.2523,  -9.4292,   3.1972,  -5.0118, -15.3422,\n",
              "          94.2373,  -8.7790,   6.6869],\n",
              "        [-14.6536,  -0.3266, -12.4800,  -1.2362,  -7.0912,  14.7625,  16.4220,\n",
              "          -8.7790, 127.2023,  -5.1626],\n",
              "        [ 25.5066,   8.5041,  -7.2879,   2.1052,  10.8148,   9.2338,  -6.2517,\n",
              "           6.6869,  -5.1626, 106.9159]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u,s,v = torch.svd(m) "
      ],
      "metadata": {
        "id": "MQLEgMhE5uV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u"
      ],
      "metadata": {
        "id": "7xwEFK8U51iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZf6fDX251tO",
        "outputId": "b004cf6f-0891-4afa-be7c-9a91a7ddcc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13.1270, 12.3738, 11.3888, 10.8720,  9.6368,  9.4977,  8.8983,  8.2431,\n",
              "         8.0310,  7.2082])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPX9mFu6513L",
        "outputId": "988850c5-a0b5-44c5-867e-b0e5042f89bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6709,  0.0154, -0.2024,  0.1273, -0.1848,  0.1235, -0.1763, -0.2076,\n",
              "         -0.6019, -0.0811],\n",
              "        [-0.0338, -0.2644, -0.2664, -0.0045,  0.2567,  0.3816,  0.4601,  0.5542,\n",
              "         -0.2423,  0.2625],\n",
              "        [-0.0573, -0.1437,  0.1717,  0.7059,  0.1439, -0.0372, -0.3018,  0.0047,\n",
              "          0.1102,  0.5683],\n",
              "        [-0.5435,  0.4917,  0.1489, -0.2505,  0.2798,  0.1925, -0.1411,  0.2472,\n",
              "          0.4085,  0.1213],\n",
              "        [-0.1837, -0.2513, -0.0775,  0.3558,  0.4889,  0.1500,  0.1911, -0.2584,\n",
              "          0.2899, -0.5672],\n",
              "        [ 0.0455, -0.0815, -0.4523,  0.1893, -0.3867,  0.1426, -0.4358,  0.4623,\n",
              "          0.2960, -0.2998],\n",
              "        [ 0.0262,  0.4405,  0.1169,  0.3670,  0.1243, -0.5006,  0.1675,  0.4394,\n",
              "         -0.2805, -0.3018],\n",
              "        [ 0.0868, -0.3209,  0.0541, -0.3193,  0.5349, -0.1934, -0.5879,  0.1789,\n",
              "         -0.2704, -0.1014],\n",
              "        [ 0.3219,  0.4969, -0.6302,  0.0589,  0.3326,  0.0997, -0.1158, -0.2864,\n",
              "         -0.0917,  0.1562],\n",
              "        [-0.3201, -0.2319, -0.4605, -0.1419,  0.0137, -0.6781,  0.1810, -0.0335,\n",
              "          0.2610,  0.2224]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 자동미분\n",
        "# 텐서에는 requires_grad라는 속성이 있어서  이것을 true로 설정하면서 자동미분기능이 활성화됨\n",
        "# requires_grad가 적용된 텐서에 다양한 계산을 하게되면 계산 그래프가 만들어지며, backward메서드를 호출하면 그래프로부터 자동으로 미분을 계산함\n",
        "x = torch.randn(100,3) \n",
        "a= torch.tensor( [1,2,3.], requires_grad = True) ;  a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIxT2mkp51_Y",
        "outputId": "5e215248-1759-4c8d-bf3c-b9d406864a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= torch.mv(x,a)\n",
        "o = y.sum() ; o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCGPsOES6pCk",
        "outputId": "4bbc2fab-b319-491a-ad62-5276f5d99332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-63.9546, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrH4W1bu8hcV",
        "outputId": "4336b28e-525d-4dfd-ad15-f609ff24d792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -1.6790,   6.2234,   2.0262,   0.1843,  -3.7172,   2.0680,  -0.8868,\n",
              "         -7.7327,  -7.7681,  -4.3122,   3.9296,   2.7129,  -0.8416,   0.6948,\n",
              "         -7.1300,  -5.2981,   1.0602,  -5.0065,  -2.2662,  -1.4891,  -9.8259,\n",
              "          3.2916,  -7.5531,  -0.5393,   3.7111,   1.7188,   1.7728,  -2.5365,\n",
              "          1.8044,  -1.3422,   3.9039,  -2.3873,   2.7519,   3.8940,  -0.1235,\n",
              "          0.3915,   3.9567,  -6.9399,  -1.2097,  -0.5016,  -4.2354,   1.1949,\n",
              "          4.6657,   2.2072,  -2.4985,  -3.5056,  -5.3671,   4.0049,  -0.7339,\n",
              "         -0.5657,  -5.3371,  -3.7756,   1.4645,   1.4231,   0.0615,   0.0887,\n",
              "          0.5977,   4.4149,  -3.1129,  -1.4848,  -2.9377,   3.5605,   2.5547,\n",
              "          3.7236,  -2.2764,  -0.2551,   1.0378,  -3.3118,  -3.7667,   3.3440,\n",
              "          5.5823,  -7.4519,  -6.8586,   5.3651,   0.2065,   2.0097,   0.3408,\n",
              "          7.1689,  -3.7455,   2.6760,   3.0943,   1.8630,  -0.4149,  -6.1737,\n",
              "         -4.2698,   4.3726,  -1.0226,   1.3489,  -1.9999,  -3.3955,  -3.6352,\n",
              "         -7.4166,   1.5312,   4.1735,   1.8928,   3.7143, -11.0438,  -2.7821,\n",
              "         -8.0361,   2.7625], grad_fn=<MvBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o.backward() # 미분을 실행"
      ],
      "metadata": {
        "id": "JXK1Eird612V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn750gLH8Q5J",
        "outputId": "4a310a18-9c17-4dc4-c64d-22cf18cfd0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9.8775, 13.6320, -4.8564])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5gu8nYL8TQT",
        "outputId": "3a5c591e-83e9-42bb-b506-95a9cb17060c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9.8775, 13.6320, -4.8564])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNlP8o3h_N1K",
        "outputId": "28cce306-a2d1-4811-bcfd-d1307db5bcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-29.2973)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad != x.sum(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_-vMlHi6_YD",
        "outputId": "c6686dcb-a1d4-49e3-b307-fea62f76501c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서는 자동으로 미분을 계산할 수 있어서 신경망 최적화에 중요한 역할을 함"
      ],
      "metadata": {
        "id": "TKOvM7Vd7Dyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7n4NyoCG7Hsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.최대우도와 선형모델 "
      ],
      "metadata": {
        "id": "uZo87jMb7M6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mle : 최대우도 추정치, 우도를 최대로 만드는 파라미터 theta\n",
        "# 계산이 쉽다는 이유로  대수우도(log likelihood)형태를 취함\n",
        "#"
      ],
      "metadata": {
        "id": "zQcyX_pQ7OaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확률적 경사하강법\n",
        "# 대수우도함수의 미분이 0이되는 방정식에 해석해가 없는경우에는 수치적으로 최적화해야함\n",
        "# 목적함수를 최소화하는 것을 목표로함\n",
        "# 최소화하는 경우의 목적함수를 손실함수라 함\n",
        "# 대수우도 함수를 최대화 하는 것이 아니라 부호를 반대로 한것을 최소화 하는 것이 목표가됨\n",
        "# 미분가능한 함수의 수치 최적화를 구하는 가장 간단한 방법이 경사하강법\n",
        "# 미분계수를 이용해서 반복적으로 최적해 나가는 방법임\n",
        "# 학습률이 크면 손실함수의 감소속도가 빠르지만 잘 수렴하지 않으면 진동이 발생할 가능성 생김\n",
        "# 학습률이 적으면 손실함수의 감소가 느리며, 수렴할때까지 많은 계산을 해야함\n",
        "# 랜덤으로 일부값(미니배치)만 사용하는 sgd(확률적 경사 하강법)을 이용 가능함\n",
        "# 데이터 규모가 큰경우에 적합함\n",
        "\n"
      ],
      "metadata": {
        "id": "HhoQA0fZ_wPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y = 1+ 2x1 + 3x2 의 파라미터를 구해보기\n"
      ],
      "metadata": {
        "id": "rdXIAY3zBoYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "w_true = torch.Tensor([1,2,3]) # 위식의 기울기와 절편\n",
        "X = torch.cat([torch.ones(100,1), torch.randn(100,2)] , dim= 1);X "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRyffXC_Chr7",
        "outputId": "d4f0bff2-7ba2-4dbe-fa51-156027f85219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000e+00,  3.0264e-01,  1.6885e+00],\n",
              "        [ 1.0000e+00,  3.0138e+00, -3.5700e-01],\n",
              "        [ 1.0000e+00, -4.5663e-01,  1.4095e+00],\n",
              "        [ 1.0000e+00, -1.5481e+00,  1.8883e+00],\n",
              "        [ 1.0000e+00, -3.0072e-02,  8.7388e-01],\n",
              "        [ 1.0000e+00, -1.6394e+00,  1.3134e+00],\n",
              "        [ 1.0000e+00, -2.4008e-03,  6.2055e-02],\n",
              "        [ 1.0000e+00,  5.1827e-02,  2.5118e-01],\n",
              "        [ 1.0000e+00,  1.3734e+00,  7.5427e-01],\n",
              "        [ 1.0000e+00,  4.5136e-01, -9.0120e-01],\n",
              "        [ 1.0000e+00, -4.8555e-03, -1.0073e+00],\n",
              "        [ 1.0000e+00,  2.3494e-02, -1.1585e+00],\n",
              "        [ 1.0000e+00, -7.7548e-01,  9.8981e-01],\n",
              "        [ 1.0000e+00, -2.7553e-01,  3.6380e-01],\n",
              "        [ 1.0000e+00, -4.1333e-01, -5.6058e-01],\n",
              "        [ 1.0000e+00,  2.9504e-01,  1.5440e+00],\n",
              "        [ 1.0000e+00,  3.0474e-01, -1.4992e+00],\n",
              "        [ 1.0000e+00, -3.9966e-02,  9.4493e-01],\n",
              "        [ 1.0000e+00, -1.7312e+00,  8.0155e-01],\n",
              "        [ 1.0000e+00, -3.1031e-02, -1.1673e-01],\n",
              "        [ 1.0000e+00, -3.3979e-01,  1.1239e+00],\n",
              "        [ 1.0000e+00,  1.3361e-01, -1.5523e-01],\n",
              "        [ 1.0000e+00, -5.2242e-01, -8.0633e-01],\n",
              "        [ 1.0000e+00, -1.6196e+00, -1.1445e+00],\n",
              "        [ 1.0000e+00, -8.0423e-01,  6.9103e-01],\n",
              "        [ 1.0000e+00, -1.3544e+00, -1.9116e+00],\n",
              "        [ 1.0000e+00, -1.3437e+00,  1.8164e-01],\n",
              "        [ 1.0000e+00, -7.7869e-01,  5.5305e-02],\n",
              "        [ 1.0000e+00, -2.3801e-01,  1.5205e-02],\n",
              "        [ 1.0000e+00, -3.3630e-01,  1.1256e-01],\n",
              "        [ 1.0000e+00, -5.8381e-02,  4.1970e-01],\n",
              "        [ 1.0000e+00, -1.2801e+00, -1.5727e+00],\n",
              "        [ 1.0000e+00,  7.4593e-01, -2.6941e-01],\n",
              "        [ 1.0000e+00,  6.9238e-01,  6.5672e-01],\n",
              "        [ 1.0000e+00,  3.7774e-01,  1.3123e+00],\n",
              "        [ 1.0000e+00,  1.0501e+00, -7.4871e-01],\n",
              "        [ 1.0000e+00,  5.1722e-01,  1.2146e+00],\n",
              "        [ 1.0000e+00,  2.2847e+00,  3.0065e-01],\n",
              "        [ 1.0000e+00, -9.4006e-01,  3.6769e-01],\n",
              "        [ 1.0000e+00, -1.7162e+00,  2.4940e-01],\n",
              "        [ 1.0000e+00, -5.5375e-01, -1.5082e+00],\n",
              "        [ 1.0000e+00,  6.1872e-01, -9.6510e-01],\n",
              "        [ 1.0000e+00,  1.0111e+00, -1.0606e+00],\n",
              "        [ 1.0000e+00,  2.0338e+00,  2.5989e-01],\n",
              "        [ 1.0000e+00, -3.1757e+00, -5.0213e-01],\n",
              "        [ 1.0000e+00,  1.2462e+00, -1.4755e+00],\n",
              "        [ 1.0000e+00,  1.0083e+00, -1.4640e+00],\n",
              "        [ 1.0000e+00, -1.0230e+00,  8.4310e-03],\n",
              "        [ 1.0000e+00, -2.0373e+00,  9.8064e-01],\n",
              "        [ 1.0000e+00, -2.5567e-01,  1.1487e+00],\n",
              "        [ 1.0000e+00, -3.0865e-01,  3.2396e-01],\n",
              "        [ 1.0000e+00, -1.5985e+00, -6.2048e-01],\n",
              "        [ 1.0000e+00,  1.0966e+00,  3.7194e-01],\n",
              "        [ 1.0000e+00, -3.2566e-01, -3.2174e+00],\n",
              "        [ 1.0000e+00,  6.7008e-01,  4.9961e-01],\n",
              "        [ 1.0000e+00,  4.5507e-01, -1.4400e+00],\n",
              "        [ 1.0000e+00,  8.2591e-01, -1.3632e+00],\n",
              "        [ 1.0000e+00, -9.6550e-01,  1.7554e+00],\n",
              "        [ 1.0000e+00,  1.9604e+00, -6.1040e-01],\n",
              "        [ 1.0000e+00, -6.7015e-01,  6.8781e-01],\n",
              "        [ 1.0000e+00,  1.8820e-01,  2.2941e+00],\n",
              "        [ 1.0000e+00, -1.1904e-01,  6.0238e-01],\n",
              "        [ 1.0000e+00,  2.8172e-01,  4.7686e-01],\n",
              "        [ 1.0000e+00,  8.1139e-01, -7.8266e-01],\n",
              "        [ 1.0000e+00, -2.4289e+00, -7.9381e-01],\n",
              "        [ 1.0000e+00, -3.4967e-01, -1.3467e+00],\n",
              "        [ 1.0000e+00, -7.7125e-01,  1.1175e+00],\n",
              "        [ 1.0000e+00,  1.8095e-01,  1.2947e-01],\n",
              "        [ 1.0000e+00, -7.6631e-01, -4.9626e-01],\n",
              "        [ 1.0000e+00, -1.1111e+00, -1.3041e+00],\n",
              "        [ 1.0000e+00,  1.5375e+00,  6.6461e-02],\n",
              "        [ 1.0000e+00,  1.7952e-01, -4.7157e-01],\n",
              "        [ 1.0000e+00, -1.2200e+00,  8.4122e-02],\n",
              "        [ 1.0000e+00, -1.0453e+00,  7.7294e-01],\n",
              "        [ 1.0000e+00,  6.8113e-01, -2.1013e+00],\n",
              "        [ 1.0000e+00, -1.9517e+00, -2.9734e-01],\n",
              "        [ 1.0000e+00,  1.2578e+00,  4.0994e-01],\n",
              "        [ 1.0000e+00, -2.1352e+00, -4.0849e-02],\n",
              "        [ 1.0000e+00,  6.6435e-01,  2.6757e-01],\n",
              "        [ 1.0000e+00, -3.8711e-01,  1.7921e+00],\n",
              "        [ 1.0000e+00, -3.5538e-01, -9.5562e-01],\n",
              "        [ 1.0000e+00, -2.6445e-01,  4.2098e-01],\n",
              "        [ 1.0000e+00,  4.3000e-01,  6.0236e-01],\n",
              "        [ 1.0000e+00, -1.0972e-01,  8.0337e-01],\n",
              "        [ 1.0000e+00, -1.0551e+00,  1.0885e+00],\n",
              "        [ 1.0000e+00, -4.9939e-01, -2.5225e-01],\n",
              "        [ 1.0000e+00, -7.5270e-01,  1.4352e+00],\n",
              "        [ 1.0000e+00,  4.7292e-01, -5.2854e-01],\n",
              "        [ 1.0000e+00, -7.3627e-01, -6.8902e-02],\n",
              "        [ 1.0000e+00,  1.4256e-01, -2.9251e-01],\n",
              "        [ 1.0000e+00,  8.6043e-02,  1.1996e+00],\n",
              "        [ 1.0000e+00, -2.7308e-01, -2.5180e-01],\n",
              "        [ 1.0000e+00, -2.9839e-01, -2.8563e-02],\n",
              "        [ 1.0000e+00, -8.7817e-01,  1.2911e+00],\n",
              "        [ 1.0000e+00,  7.6074e-02,  2.1687e-01],\n",
              "        [ 1.0000e+00, -5.0680e-01,  5.4367e-01],\n",
              "        [ 1.0000e+00,  1.2547e+00, -1.0586e+00],\n",
              "        [ 1.0000e+00,  5.1294e-01,  7.2282e-01],\n",
              "        [ 1.0000e+00, -1.3685e+00, -1.4217e-01],\n",
              "        [ 1.0000e+00,  1.8204e+00,  2.1871e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.mv(X, w_true) + torch.randn(100) * 0.5 ;y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GJO6LEVCrSg",
        "outputId": "81148a33-2fbe-4cb9-ac2f-56281f873e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7.0387,  4.7634,  4.3648,  2.5690,  3.6141,  2.3951,  1.1191,  1.0221,\n",
              "         5.8928, -1.3757, -1.6036, -2.3283,  3.7007,  1.8242, -1.2647,  6.0826,\n",
              "        -2.9351,  4.1109,  0.1206,  1.6292,  3.2002,  1.2211, -3.3550, -5.1352,\n",
              "         1.0322, -7.5687, -1.3146,  0.0505,  0.4828,  0.6365,  1.7273, -6.6473,\n",
              "         2.2028,  4.1371,  5.4199,  0.7645,  5.4809,  6.8487,  0.6611, -1.6329,\n",
              "        -4.9646, -0.9458,  0.1057,  6.0386, -6.4018, -1.0593, -1.8065, -0.5978,\n",
              "         0.0853,  3.1510,  0.8854, -3.7973,  5.0156, -9.6042,  3.7093, -2.4936,\n",
              "        -1.8619,  5.0426,  3.4686,  2.0843,  8.3638,  2.6321,  2.1275,  0.0461,\n",
              "        -6.2224, -4.1168,  3.3733,  1.1363, -1.5954, -5.6294,  3.9052, -0.3891,\n",
              "         0.1640,  1.2006, -3.9596, -4.5119,  5.1655, -3.5877,  2.0833,  5.8799,\n",
              "        -2.3284,  1.2376,  2.7952,  2.7142,  2.4482, -0.6767,  3.7698,  0.7685,\n",
              "        -1.4449,  0.2540,  5.6239, -0.0124,  0.0856,  4.1160,  1.2447,  1.8554,\n",
              "        -0.3709,  4.2999, -2.3005, 11.4022])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기 하강으로 최적화하기위해 파라미터 tensor를 난수로 초기화해서 생성\n",
        "w= torch.randn(3, requires_grad =True) ;w "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlbq0jPFC4VH",
        "outputId": "4d809432-ed6a-454c-9d01-3b918230e5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8532,  0.0689, -1.2022], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJORBhm7HHzD",
        "outputId": "b13ccd0a-46ef-4e39-9d99-07dac7a5a66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8532,  0.0689, -1.2022])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.1 "
      ],
      "metadata": {
        "id": "pTFqeChKDaMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 경사하강법으로 파라미터 최적화\n",
        "# 손실함수의 로그\n",
        "losses = []\n",
        "\n",
        "for epoch in range(100) : \n",
        "  w.grad = None # 전회의 backward메서드로 계산된 경사값을 초기화\n",
        "  y_pred = torch.mv(X, w)  # w에 대한 backward가 진행될 예정임\n",
        "  loss = torch.mean((y-y_pred)**2)  # loss값이 최종값\n",
        "  loss.backward()  # mse loss와 w에 의한 미분을 계산 \n",
        "\n",
        "  # 경사를 갱신\n",
        "  w.data = w.data - gamma * w.grad.data \n",
        "  losses.append(loss.item())"
      ],
      "metadata": {
        "id": "5FQtPNqcDonc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZDvcW61IIbe",
        "outputId": "afce7a86-5841-4a14-c367-7edaca949d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25.37399673461914,\n",
              " 16.262487411499023,\n",
              " 10.468910217285156,\n",
              " 6.778658866882324,\n",
              " 4.4243927001953125,\n",
              " 2.9202470779418945,\n",
              " 1.9579471349716187,\n",
              " 1.3415312767028809,\n",
              " 0.9462174773216248,\n",
              " 0.6924230456352234,\n",
              " 0.5293183326721191,\n",
              " 0.4243957996368408,\n",
              " 0.35683852434158325,\n",
              " 0.3133019506931305,\n",
              " 0.28522148728370667,\n",
              " 0.2670951783657074,\n",
              " 0.25538501143455505,\n",
              " 0.2478141039609909,\n",
              " 0.24291545152664185,\n",
              " 0.23974356055259705,\n",
              " 0.23768813908100128,\n",
              " 0.2363552302122116,\n",
              " 0.23549027740955353,\n",
              " 0.23492853343486786,\n",
              " 0.23456346988677979,\n",
              " 0.23432601988315582,\n",
              " 0.23417140543460846,\n",
              " 0.2340707778930664,\n",
              " 0.2340051531791687,\n",
              " 0.23396232724189758,\n",
              " 0.23393438756465912,\n",
              " 0.23391613364219666,\n",
              " 0.2339041829109192,\n",
              " 0.233896404504776,\n",
              " 0.2338912934064865,\n",
              " 0.2338879257440567,\n",
              " 0.2338857203722,\n",
              " 0.2338842898607254,\n",
              " 0.2338833212852478,\n",
              " 0.23388271033763885,\n",
              " 0.23388227820396423,\n",
              " 0.23388203978538513,\n",
              " 0.2338818907737732,\n",
              " 0.23388174176216125,\n",
              " 0.23388166725635529,\n",
              " 0.2338816076517105,\n",
              " 0.23388156294822693,\n",
              " 0.23388154804706573,\n",
              " 0.23388154804706573,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388147354125977,\n",
              " 0.23388153314590454,\n",
              " 0.23388147354125977,\n",
              " 0.23388153314590454,\n",
              " 0.23388147354125977,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388153314590454,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388148844242096,\n",
              " 0.23388147354125977,\n",
              " 0.23388148844242096,\n",
              " 0.23388147354125977,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388148844242096,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrjG3K_wF0Dj",
        "outputId": "ed603bde-cd0f-4308-d87d-4f0579a59d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1921e-07, -2.8997e-07, -1.8462e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.mv(X,w) ;y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjp6EnbeF1Rm",
        "outputId": "e27acd88-a967-4364-f3b8-f681af800c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0085, -0.0246,  1.1179,  1.0199,  0.5109,  0.0774, -0.4930,  1.6154,\n",
              "         0.7743, -0.8198,  0.9079, -0.1560,  0.5918, -0.7909, -0.0102,  0.3425,\n",
              "        -0.1615, -0.3225,  0.5031, -0.5669,  1.2314,  1.3078,  1.0038, -0.8805,\n",
              "         0.0408,  1.0552,  0.6817, -1.4399,  0.3638,  0.0505, -0.1903, -0.5112,\n",
              "         0.3961,  0.5551,  0.2398,  0.3563,  0.0303,  0.1338, -0.0182, -0.4791,\n",
              "         0.3137,  1.0918,  0.9052,  1.3500,  0.1977,  0.7091,  0.5913,  0.2823,\n",
              "         0.5739, -0.0811,  0.8663,  0.2972,  0.0144,  0.5480, -0.6056, -0.1406,\n",
              "        -0.3156,  0.9369,  0.4297,  0.5141,  0.4598,  0.3059, -0.1213, -0.4197,\n",
              "         0.5934,  0.2481,  0.6694,  0.3124,  0.2208, -0.0794, -0.1778, -0.1519,\n",
              "         0.1830,  0.5452,  0.7308,  0.4318,  1.2688,  0.5388,  1.0301,  0.9696,\n",
              "         0.6760,  0.8281,  0.9249,  0.3368,  0.4737,  0.8321,  2.1106,  2.0753,\n",
              "         0.7072,  0.1981,  0.1949, -0.4387,  1.6918, -0.8633,  0.1670, -0.2787,\n",
              "        -0.3919,  0.0262, -1.0644,  0.5378], grad_fn=<MvBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y-y_pred)**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JblyZQvnF33l",
        "outputId": "d3932587-c242-4a72-f98c-7956893ad8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.6079e+00, 7.6586e+00, 7.1294e+00, 6.4358e-04, 3.9447e+00, 1.6313e-01,\n",
              "        5.0902e+00, 1.2968e+01, 7.3846e+00, 5.6073e+00, 5.2727e+00, 1.0720e+01,\n",
              "        1.3198e+01, 4.0561e-01, 7.4955e-02, 8.4345e-01, 4.3804e+00, 1.3176e+01,\n",
              "        9.0718e-01, 2.9719e+01, 9.8230e+00, 1.4751e+01, 5.6378e+00, 1.2422e-01,\n",
              "        1.2093e+01, 1.7371e+01, 7.0064e-01, 7.1437e+00, 2.1628e-01, 5.5870e+00,\n",
              "        2.2913e-01, 1.3239e-02, 3.7579e-01, 3.4225e+00, 9.2970e-03, 6.9426e+00,\n",
              "        7.8194e+00, 1.1184e+00, 2.7658e+01, 1.0102e+01, 4.7930e+00, 5.5973e+00,\n",
              "        6.9926e+00, 5.0427e-02, 5.2780e+00, 8.6067e+00, 2.2299e-03, 2.7483e+01,\n",
              "        4.4836e-01, 1.2498e+00, 1.0313e+01, 3.2075e+01, 1.1705e+01, 3.4437e+01,\n",
              "        6.6149e-01, 3.2013e+01, 7.0291e-01, 4.2675e-01, 1.4334e+00, 8.1247e-01,\n",
              "        2.3702e+01, 1.3259e+01, 7.4191e+00, 5.1107e-01, 1.6317e+01, 8.5295e+00,\n",
              "        1.1126e+01, 5.4669e+01, 1.6920e+01, 4.7858e-01, 5.9750e+00, 1.6049e+00,\n",
              "        4.7558e-02, 3.5804e+00, 1.2385e-01, 2.2925e+00, 1.0812e+01, 7.7651e-01,\n",
              "        6.3286e+00, 1.7061e+00, 8.4882e+00, 7.8041e-01, 1.1739e+00, 1.0125e+00,\n",
              "        8.5823e+00, 1.2989e+01, 9.0905e-01, 3.7458e+00, 1.7406e+00, 2.4204e+01,\n",
              "        1.2171e+01, 3.2634e-02, 8.2284e+00, 3.1660e+01, 1.1490e+00, 6.8036e+01,\n",
              "        5.3203e+00, 7.9723e+00, 2.4526e-02, 1.5475e+01],\n",
              "       grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean((y-y_pred)**2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sui2KGZfF5wO",
        "outputId": "bd1cc1fb-66fb-4c25-a7f2-1844c75fb3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.4934, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.mean((y-y_pred)**2) \n",
        "loss.backward() "
      ],
      "metadata": {
        "id": "A-PcTQdCF7Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MSZIdcfHUXf",
        "outputId": "fb2227c9-0a84-457a-9138-83af4ab9a777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.493419647216797"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVggXGGwHXxT",
        "outputId": "0ea582e8-e12e-410e-843b-0a36bbc0b4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.4934, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt \n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "nLeLChV5HY1i",
        "outputId": "f07cc41a-3d8f-4373-afb1-791ced1aab32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f38eb0c8850>]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBEd1nXJHhaS",
        "outputId": "13977d31-0c9a-426a-9b8f-0c96b20f0c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9624, 1.9220, 3.0801], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치로 선형회귀 모델 만들기\n",
        "# 이전에는 자동미분을 할때 이외에는 모델 구축이나 경사 하강법 계산을 모두 직접함\n",
        "# 신경망을 풀때 공통적으로 사용되는 계산이므로, 파이토치에는 이 계산들을 쉽게 작성할 수 있게 해주는 모듈이 포함됨\n"
      ],
      "metadata": {
        "id": "8t9xfs4yHlnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim \n",
        "# Linear 층을 작성, 절편은 회귀계수에 포함\n",
        "# 입력차원을 3으로 하고, bias를 false로 함\n",
        "net = nn.Linear(in_features = 3, out_features = 1, bias= False)  # 선형결합 계산하는 클래스 회귀계수나 절편등의 파라미터를 포함\n",
        "# nn.Module의 서브클래스로 sgd등의 최적화기와 연계하거나 학습결과 파라미터를 저장하는 등 다양한 처리 가능\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.1) \n",
        "loss_fn = nn.MSELoss() \n",
        "# 모델의 구축 : torch.nn\n",
        "# 최적화 : torch.optim\n"
      ],
      "metadata": {
        "id": "lf0Uoy6qKgzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = [] \n",
        "for epoc in range(100): \n",
        "  optimizer.zero_grad() #  전회의 backward메서드로 계산된 경사값을 초기화\n",
        "  y_pred = net(X) \n",
        "  loss = loss_fn(y_pred.view_as(y) , y) \n",
        "  # y_pred는 (n,1)같은 shape를 지니고있으므려 (n,) 형태로 변경할 필요가 있음\n",
        "  loss.backward() \n",
        "  optimizer.step() # 경사를 갱신한다.\n",
        "  losses.append(loss.item()) # 수렴확인을 위한 loss를 기록"
      ],
      "metadata": {
        "id": "GYgYi7lcLMlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kF7abhyMtBc",
        "outputId": "f728c363-2366-4c7e-aa28-9e917a1a4352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.62334442138672,\n",
              " 12.72098159790039,\n",
              " 8.279315948486328,\n",
              " 5.419905185699463,\n",
              " 3.578310251235962,\n",
              " 2.391711473464966,\n",
              " 1.6268008947372437,\n",
              " 1.1334912776947021,\n",
              " 0.8151913285255432,\n",
              " 0.609712541103363,\n",
              " 0.4769984185695648,\n",
              " 0.3912368714809418,\n",
              " 0.33578699827194214,\n",
              " 0.2999158799648285,\n",
              " 0.2766972780227661,\n",
              " 0.26165971159935,\n",
              " 0.25191497802734375,\n",
              " 0.2455962747335434,\n",
              " 0.2414965033531189,\n",
              " 0.23883487284183502,\n",
              " 0.23710571229457855,\n",
              " 0.23598161339759827,\n",
              " 0.23525038361549377,\n",
              " 0.2347744107246399,\n",
              " 0.23446431756019592,\n",
              " 0.23426219820976257,\n",
              " 0.2341303825378418,\n",
              " 0.23404432833194733,\n",
              " 0.23398809134960175,\n",
              " 0.23395134508609772,\n",
              " 0.23392732441425323,\n",
              " 0.23391152918338776,\n",
              " 0.2339012175798416,\n",
              " 0.2338944673538208,\n",
              " 0.23389004170894623,\n",
              " 0.23388710618019104,\n",
              " 0.23388519883155823,\n",
              " 0.23388393223285675,\n",
              " 0.2338830977678299,\n",
              " 0.2338826060295105,\n",
              " 0.23388221859931946,\n",
              " 0.23388199508190155,\n",
              " 0.23388183116912842,\n",
              " 0.23388169705867767,\n",
              " 0.2338816523551941,\n",
              " 0.23388159275054932,\n",
              " 0.23388159275054932,\n",
              " 0.23388153314590454,\n",
              " 0.23388154804706573,\n",
              " 0.23388151824474335,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388151824474335,\n",
              " 0.23388148844242096,\n",
              " 0.23388148844242096,\n",
              " 0.23388148844242096,\n",
              " 0.23388153314590454,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388151824474335,\n",
              " 0.23388151824474335,\n",
              " 0.23388154804706573,\n",
              " 0.23388153314590454,\n",
              " 0.23388151824474335,\n",
              " 0.23388153314590454,\n",
              " 0.23388148844242096,\n",
              " 0.23388148844242096,\n",
              " 0.23388148844242096,\n",
              " 0.23388148844242096,\n",
              " 0.23388151824474335,\n",
              " 0.23388148844242096,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454,\n",
              " 0.23388153314590454]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(net.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tojz-ep1M0pe",
        "outputId": "080fafa3-19af-4baf-f0f6-fe78b6e61042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.9624, 1.9220, 3.0801]], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로지스틱 회귀\n",
        "# 로지스틱 회귀의 최대 우도 추정\n",
        "# 파이토치를 사용한 로지스틱 회귀분석\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.datasets import load_iris \n",
        "iris = load_iris() \n",
        "X = iris.data[:100] \n",
        "y = iris.target[:100] "
      ],
      "metadata": {
        "id": "4jB-lMpYM3Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= torch.tensor(X,  dtype = torch.float32) ;X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRjeTFmAONh6",
        "outputId": "3fbb6bee-0e9b-4cf5-d058-272f6d32ddbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
              "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
              "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
              "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
              "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
              "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
              "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
              "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
              "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
              "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
              "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
              "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
              "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
              "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
              "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
              "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
              "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
              "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
              "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
              "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
              "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
              "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
              "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
              "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
              "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
              "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
              "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
              "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
              "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
              "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
              "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
              "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
              "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
              "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
              "        [4.9000, 3.1000, 1.5000, 0.2000],\n",
              "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
              "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
              "        [4.9000, 3.6000, 1.4000, 0.1000],\n",
              "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
              "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
              "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
              "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
              "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
              "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
              "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
              "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
              "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
              "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
              "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
              "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
              "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
              "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
              "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
              "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
              "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
              "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
              "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
              "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
              "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
              "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
              "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
              "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
              "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
              "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
              "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
              "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
              "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
              "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
              "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
              "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
              "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
              "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
              "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
              "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
              "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
              "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
              "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
              "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
              "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
              "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
              "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
              "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
              "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
              "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
              "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
              "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
              "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
              "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
              "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
              "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
              "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
              "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
              "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
              "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
              "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
              "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
              "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
              "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
              "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
              "        [5.7000, 2.8000, 4.1000, 1.3000]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= torch.tensor(y, dtype = torch.float32) ; y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzDZvHknORYX",
        "outputId": "5cf3e290-8751-4f99-8619-876a76eab29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net= nn.Linear(4,1) # iris데이터는 4차원\n",
        "loss_fn = nn.BCEWithLogitsLoss() \n",
        "optimizer = optim.SGD(net.parameters(), lr =0.25) "
      ],
      "metadata": {
        "id": "2cgpHEvpOV9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(100): \n",
        "  optimizer.zero_grad() \n",
        "  y_pred = net(X) \n",
        "  loss = loss_fn(y_pred.view_as(y), y) \n",
        "  loss.backward() \n",
        "  optimizer.step() #경사를 갱신함\n",
        "  losses.append(loss.item())"
      ],
      "metadata": {
        "id": "TheQFpN4OrA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt \n",
        " plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "2d-G-UA0PDTy",
        "outputId": "a42ad701-a02b-4060-a3ba-e53d552efff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f38dc194350>]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 작성\n",
        "h= net(X)\n",
        "prob = nn.functional.sigmoid(h) \n",
        "prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO-Zc04AOifJ",
        "outputId": "c4ef8da5-7d90-411f-a308-37aa9683fc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0175],\n",
              "        [0.0361],\n",
              "        [0.0254],\n",
              "        [0.0462],\n",
              "        [0.0163],\n",
              "        [0.0219],\n",
              "        [0.0292],\n",
              "        [0.0259],\n",
              "        [0.0530],\n",
              "        [0.0350],\n",
              "        [0.0144],\n",
              "        [0.0356],\n",
              "        [0.0338],\n",
              "        [0.0234],\n",
              "        [0.0041],\n",
              "        [0.0065],\n",
              "        [0.0093],\n",
              "        [0.0198],\n",
              "        [0.0187],\n",
              "        [0.0168],\n",
              "        [0.0319],\n",
              "        [0.0216],\n",
              "        [0.0086],\n",
              "        [0.0603],\n",
              "        [0.0662],\n",
              "        [0.0521],\n",
              "        [0.0406],\n",
              "        [0.0205],\n",
              "        [0.0188],\n",
              "        [0.0478],\n",
              "        [0.0512],\n",
              "        [0.0266],\n",
              "        [0.0086],\n",
              "        [0.0058],\n",
              "        [0.0395],\n",
              "        [0.0175],\n",
              "        [0.0114],\n",
              "        [0.0152],\n",
              "        [0.0382],\n",
              "        [0.0245],\n",
              "        [0.0168],\n",
              "        [0.0937],\n",
              "        [0.0299],\n",
              "        [0.0457],\n",
              "        [0.0444],\n",
              "        [0.0429],\n",
              "        [0.0185],\n",
              "        [0.0332],\n",
              "        [0.0152],\n",
              "        [0.0237],\n",
              "        [0.9820],\n",
              "        [0.9823],\n",
              "        [0.9913],\n",
              "        [0.9868],\n",
              "        [0.9909],\n",
              "        [0.9906],\n",
              "        [0.9891],\n",
              "        [0.9319],\n",
              "        [0.9860],\n",
              "        [0.9797],\n",
              "        [0.9708],\n",
              "        [0.9800],\n",
              "        [0.9780],\n",
              "        [0.9924],\n",
              "        [0.9324],\n",
              "        [0.9743],\n",
              "        [0.9911],\n",
              "        [0.9703],\n",
              "        [0.9955],\n",
              "        [0.9717],\n",
              "        [0.9951],\n",
              "        [0.9661],\n",
              "        [0.9971],\n",
              "        [0.9914],\n",
              "        [0.9762],\n",
              "        [0.9785],\n",
              "        [0.9921],\n",
              "        [0.9957],\n",
              "        [0.9902],\n",
              "        [0.9137],\n",
              "        [0.9707],\n",
              "        [0.9593],\n",
              "        [0.9644],\n",
              "        [0.9982],\n",
              "        [0.9920],\n",
              "        [0.9838],\n",
              "        [0.9880],\n",
              "        [0.9914],\n",
              "        [0.9731],\n",
              "        [0.9830],\n",
              "        [0.9908],\n",
              "        [0.9893],\n",
              "        [0.9745],\n",
              "        [0.9363],\n",
              "        [0.9850],\n",
              "        [0.9741],\n",
              "        [0.9797],\n",
              "        [0.9786],\n",
              "        [0.8641],\n",
              "        [0.9778]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9TawNBdPWhL",
        "outputId": "1a194ff2-b1d4-4937-8c6b-1cf0c2cb59f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.0279],\n",
              "        [-3.2833],\n",
              "        [-3.6456],\n",
              "        [-3.0277],\n",
              "        [-4.1000],\n",
              "        [-3.7975],\n",
              "        [-3.5024],\n",
              "        [-3.6280],\n",
              "        [-2.8821],\n",
              "        [-3.3165],\n",
              "        [-4.2283],\n",
              "        [-3.3002],\n",
              "        [-3.3528],\n",
              "        [-3.7327],\n",
              "        [-5.4828],\n",
              "        [-5.0330],\n",
              "        [-4.6698],\n",
              "        [-3.9036],\n",
              "        [-3.9594],\n",
              "        [-4.0664],\n",
              "        [-3.4113],\n",
              "        [-3.8152],\n",
              "        [-4.7528],\n",
              "        [-2.7469],\n",
              "        [-2.6461],\n",
              "        [-2.9020],\n",
              "        [-3.1613],\n",
              "        [-3.8646],\n",
              "        [-3.9557],\n",
              "        [-2.9914],\n",
              "        [-2.9193],\n",
              "        [-3.5988],\n",
              "        [-4.7508],\n",
              "        [-5.1360],\n",
              "        [-3.1922],\n",
              "        [-4.0282],\n",
              "        [-4.4653],\n",
              "        [-4.1694],\n",
              "        [-3.2271],\n",
              "        [-3.6828],\n",
              "        [-4.0668],\n",
              "        [-2.2689],\n",
              "        [-3.4811],\n",
              "        [-3.0397],\n",
              "        [-3.0699],\n",
              "        [-3.1042],\n",
              "        [-3.9727],\n",
              "        [-3.3727],\n",
              "        [-4.1734],\n",
              "        [-3.7191],\n",
              "        [ 3.9984],\n",
              "        [ 4.0156],\n",
              "        [ 4.7406],\n",
              "        [ 4.3131],\n",
              "        [ 4.6867],\n",
              "        [ 4.6589],\n",
              "        [ 4.5039],\n",
              "        [ 2.6159],\n",
              "        [ 4.2563],\n",
              "        [ 3.8760],\n",
              "        [ 3.5051],\n",
              "        [ 3.8896],\n",
              "        [ 3.7930],\n",
              "        [ 4.8729],\n",
              "        [ 2.6242],\n",
              "        [ 3.6357],\n",
              "        [ 4.7083],\n",
              "        [ 3.4859],\n",
              "        [ 5.3950],\n",
              "        [ 3.5377],\n",
              "        [ 5.3169],\n",
              "        [ 3.3492],\n",
              "        [ 5.8315],\n",
              "        [ 4.7513],\n",
              "        [ 3.7118],\n",
              "        [ 3.8175],\n",
              "        [ 4.8340],\n",
              "        [ 5.4439],\n",
              "        [ 4.6159],\n",
              "        [ 2.3593],\n",
              "        [ 3.5014],\n",
              "        [ 3.1591],\n",
              "        [ 3.2983],\n",
              "        [ 6.3025],\n",
              "        [ 4.8180],\n",
              "        [ 4.1053],\n",
              "        [ 4.4142],\n",
              "        [ 4.7466],\n",
              "        [ 3.5875],\n",
              "        [ 4.0592],\n",
              "        [ 4.6801],\n",
              "        [ 4.5279],\n",
              "        [ 3.6434],\n",
              "        [ 2.6881],\n",
              "        [ 4.1865],\n",
              "        [ 3.6264],\n",
              "        [ 3.8777],\n",
              "        [ 3.8215],\n",
              "        [ 1.8494],\n",
              "        [ 3.7866]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = prob>0.5; y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DmPdCaYPTVs",
        "outputId": "a6b4c206-0d19-4f21-9939-9f07bc30c9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y.byte() == y_pred.view_as(y)).sum().item() #100개의 샘플데이터가 정상적으로 이루어짐"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8P_6yARPbRV",
        "outputId": "884236cd-2a4c-4c5f-bb32-4b1cbadae7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중분류를 위한 로지스틱 회귀분석\n",
        "import torch \n",
        "from torch import nn, optim \n",
        "from sklearn.datasets  import load_digits \n",
        "digits = load_digits() "
      ],
      "metadata": {
        "id": "RK5fTAJmPg0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= digits.data ;X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKdnDLwQPwFD",
        "outputId": "1a20971a-6e79-4785-aa30-9d6021182702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IhgAI7eP0WK",
        "outputId": "791b6651-0440-46a4-fdfe-7791cfabfd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=digits.target;y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt7niltuPx8_",
        "outputId": "fec4e092-aeda-42cc-ae89-054031aa27be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUfBWjjQkCG",
        "outputId": "4fec359d-8a0c-4e6a-aea3-d17d82ea48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.tensor(X, dtype = torch.float32) \n",
        "y=torch.tensor(y, dtype = torch.int64)\n",
        "# crossentropy 는 y를 int64로 받음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7EcHSojPzP_",
        "outputId": "1a9ce184-4df8-4d92-a41f-953f13ba1ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X.size()[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_pVy6EeQFrX",
        "outputId": "6c1b501e-5406-45ba-fb56-78082f5b36b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Linear(X.size()[1], 10) "
      ],
      "metadata": {
        "id": "VbXS8ZqgP_VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss() "
      ],
      "metadata": {
        "id": "135jr8toQHkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr = 0.01) "
      ],
      "metadata": {
        "id": "kcNMur55QKMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses= [] \n",
        "for epoc in range(100): \n",
        "  optimizer.zero_grad() \n",
        "  y_pred = net(X) \n",
        "  loss = loss_fn(y_pred, y) \n",
        "  loss.backward() \n",
        "  optimizer.step()\n",
        "\n",
        "  losses.append(loss.item()) \n"
      ],
      "metadata": {
        "id": "ja4w5kxzQNBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_mZQpwUQZjr",
        "outputId": "270a4b38-423f-48fa-9f84-1ba8aff55f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.5032758712768555,\n",
              " 4.410614013671875,\n",
              " 2.943326711654663,\n",
              " 2.3195183277130127,\n",
              " 1.9333683252334595,\n",
              " 1.6767441034317017,\n",
              " 1.483318567276001,\n",
              " 1.3245848417282104,\n",
              " 1.1969913244247437,\n",
              " 1.0899062156677246,\n",
              " 1.0013080835342407,\n",
              " 0.9259556531906128,\n",
              " 0.8621560335159302,\n",
              " 0.8073126077651978,\n",
              " 0.7599852681159973,\n",
              " 0.7187368869781494,\n",
              " 0.6825212240219116,\n",
              " 0.6504731178283691,\n",
              " 0.6219143867492676,\n",
              " 0.5963071584701538,\n",
              " 0.5732167959213257,\n",
              " 0.5522924661636353,\n",
              " 0.5332424640655518,\n",
              " 0.5158257484436035,\n",
              " 0.4998386800289154,\n",
              " 0.4851102828979492,\n",
              " 0.4714943766593933,\n",
              " 0.4588668644428253,\n",
              " 0.44712045788764954,\n",
              " 0.436163067817688,\n",
              " 0.4259147644042969,\n",
              " 0.4163057506084442,\n",
              " 0.4072752892971039,\n",
              " 0.39876994490623474,\n",
              " 0.39074277877807617,\n",
              " 0.38315218687057495,\n",
              " 0.37596121430397034,\n",
              " 0.36913731694221497,\n",
              " 0.36265113949775696,\n",
              " 0.35647645592689514,\n",
              " 0.3505898714065552,\n",
              " 0.344970166683197,\n",
              " 0.3395983576774597,\n",
              " 0.334457129240036,\n",
              " 0.32953089475631714,\n",
              " 0.32480528950691223,\n",
              " 0.3202674686908722,\n",
              " 0.3159056007862091,\n",
              " 0.3117087781429291,\n",
              " 0.3076671063899994,\n",
              " 0.3037715554237366,\n",
              " 0.30001360177993774,\n",
              " 0.29638558626174927,\n",
              " 0.2928803265094757,\n",
              " 0.2894912362098694,\n",
              " 0.28621214628219604,\n",
              " 0.2830374836921692,\n",
              " 0.27996185421943665,\n",
              " 0.27698034048080444,\n",
              " 0.27408841252326965,\n",
              " 0.27128174901008606,\n",
              " 0.2685563564300537,\n",
              " 0.26590853929519653,\n",
              " 0.2633346915245056,\n",
              " 0.2608316242694855,\n",
              " 0.258396178483963,\n",
              " 0.2560255229473114,\n",
              " 0.2537167966365814,\n",
              " 0.2514675557613373,\n",
              " 0.24927525222301483,\n",
              " 0.24713768064975739,\n",
              " 0.24505263566970825,\n",
              " 0.24301807582378387,\n",
              " 0.24103204905986786,\n",
              " 0.23909272253513336,\n",
              " 0.23719832301139832,\n",
              " 0.2353471964597702,\n",
              " 0.23353785276412964,\n",
              " 0.23176869750022888,\n",
              " 0.2300383299589157,\n",
              " 0.22834539413452148,\n",
              " 0.2266886681318283,\n",
              " 0.22506685554981232,\n",
              " 0.2234787791967392,\n",
              " 0.2219233363866806,\n",
              " 0.22039945423603058,\n",
              " 0.21890613436698914,\n",
              " 0.2174423635005951,\n",
              " 0.216007262468338,\n",
              " 0.2145998775959015,\n",
              " 0.21321938931941986,\n",
              " 0.21186496317386627,\n",
              " 0.21053580939769745,\n",
              " 0.2092311978340149,\n",
              " 0.20795033872127533,\n",
              " 0.2066926211118698,\n",
              " 0.20545729994773865,\n",
              " 0.20424379408359528,\n",
              " 0.20305149257183075,\n",
              " 0.20187973976135254]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_,y_pred = torch.max(net(X), 1) ; y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PQLCLkPRCid",
        "outputId": "7b309b19-f6b1-46ea-89bd-c071489dca24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2,  ..., 8, 9, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred == y).sum().item() / len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otYkZZlqSe8e",
        "outputId": "16875482-dae0-4d11-b7b7-8bc6b9b71ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9449081803005008"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xMj6krEdSiS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.다층퍼셉트론 "
      ],
      "metadata": {
        "id": "MO09IYbTUMSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import ReLU6\n",
        "# mlp구축과 학습\n",
        "# mlp는 선형 계층을 연결한것\n",
        "# 첫번째 층은 입력층, 마지막층은 출력층, 중간중은 숨김층\n",
        "# 단순히 선형계층을 연결하기만 하면 결과적으로 전체가 선형함수가 되어버리므로 각 층의 출력에는 활성화 함수라는 비선형 함수를 적용해서 전체적으로 비선형 함수가 되게함\n",
        "import torch \n",
        "from torch import nn \n",
        "net = nn.Sequential( # 층이 일직선으로tkgdls gudxodml tlsrudakd: vlemvhdnjemgud\n",
        "    nn.Linear(64,32), \n",
        "    nn.ReLU(), \n",
        "    nn.Linear(32,16), \n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16,10) \n",
        ")"
      ],
      "metadata": {
        "id": "4ILyeiNCUOF2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FFN미분을 구할때에는 역전파라고 하는 동적 계획법 알고리즘을 사용함\n",
        "# 파이토치에서 미분을 구하는 메소드명이 backward인것도 이런 이유때문\n",
        "import torch \n",
        "from torch import nn, optim\n",
        "from sklearn.datasets import load_digits \n",
        "digits = load_digits() \n",
        "X = digits.data \n",
        "y = digits.target \n",
        "X= torch.tensor(X, dtype = torch.float32) \n",
        "y= torch.tensor(y, dtype = torch.int64) \n",
        "loss_fn = nn.CrossEntropyLoss() \n",
        "optimizer = optim.Adam(net.parameters()) \n",
        "losses = [] \n",
        "for epoc in range(100): \n",
        "  optimizer.zero_grad() \n",
        "  y_pred = net(X)\n",
        "  loss = loss_fn(y_pred, y) \n",
        "  loss.backward() \n",
        "  optimizer.step() \n",
        "  losses.append(loss.item())"
      ],
      "metadata": {
        "id": "-dgr9YggW3Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR8C6EyVXN9N",
        "outputId": "87d16395-55c7-48ae-d89c-b3471ba3b5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.4846699237823486,\n",
              " 2.397409677505493,\n",
              " 2.332463264465332,\n",
              " 2.284149169921875,\n",
              " 2.2473833560943604,\n",
              " 2.2183518409729004,\n",
              " 2.1935582160949707,\n",
              " 2.1706185340881348,\n",
              " 2.1478185653686523,\n",
              " 2.124647378921509,\n",
              " 2.100263833999634,\n",
              " 2.0741028785705566,\n",
              " 2.0464210510253906,\n",
              " 2.0174050331115723,\n",
              " 1.9873685836791992,\n",
              " 1.9565163850784302,\n",
              " 1.9249298572540283,\n",
              " 1.8931535482406616,\n",
              " 1.8611427545547485,\n",
              " 1.8286843299865723,\n",
              " 1.7956715822219849,\n",
              " 1.7619787454605103,\n",
              " 1.7276928424835205,\n",
              " 1.6929609775543213,\n",
              " 1.658333420753479,\n",
              " 1.6238954067230225,\n",
              " 1.5897760391235352,\n",
              " 1.556046485900879,\n",
              " 1.522337555885315,\n",
              " 1.4884265661239624,\n",
              " 1.4543514251708984,\n",
              " 1.4202373027801514,\n",
              " 1.3862619400024414,\n",
              " 1.3527482748031616,\n",
              " 1.319637417793274,\n",
              " 1.2868990898132324,\n",
              " 1.2544012069702148,\n",
              " 1.2221498489379883,\n",
              " 1.1900120973587036,\n",
              " 1.1581236124038696,\n",
              " 1.1266553401947021,\n",
              " 1.0956625938415527,\n",
              " 1.0652254819869995,\n",
              " 1.035231113433838,\n",
              " 1.0056020021438599,\n",
              " 0.9763563871383667,\n",
              " 0.9475915431976318,\n",
              " 0.9192810654640198,\n",
              " 0.8914342522621155,\n",
              " 0.8640934824943542,\n",
              " 0.8371906280517578,\n",
              " 0.8105596303939819,\n",
              " 0.7843276262283325,\n",
              " 0.7585864663124084,\n",
              " 0.7333838939666748,\n",
              " 0.7087947130203247,\n",
              " 0.6847993731498718,\n",
              " 0.6613276600837708,\n",
              " 0.6384857296943665,\n",
              " 0.6163219213485718,\n",
              " 0.5947891473770142,\n",
              " 0.5739333629608154,\n",
              " 0.5538122653961182,\n",
              " 0.5345190763473511,\n",
              " 0.5159085392951965,\n",
              " 0.4979884624481201,\n",
              " 0.48085370659828186,\n",
              " 0.4645916819572449,\n",
              " 0.4491059184074402,\n",
              " 0.43435245752334595,\n",
              " 0.42026278376579285,\n",
              " 0.40678444504737854,\n",
              " 0.39391574263572693,\n",
              " 0.3816063404083252,\n",
              " 0.3698950707912445,\n",
              " 0.35871708393096924,\n",
              " 0.348053514957428,\n",
              " 0.3378896713256836,\n",
              " 0.328214168548584,\n",
              " 0.31900179386138916,\n",
              " 0.31020960211753845,\n",
              " 0.3018229901790619,\n",
              " 0.29378730058670044,\n",
              " 0.28611990809440613,\n",
              " 0.27882057428359985,\n",
              " 0.271846741437912,\n",
              " 0.265184223651886,\n",
              " 0.2588120698928833,\n",
              " 0.25273412466049194,\n",
              " 0.24689677357673645,\n",
              " 0.24128496646881104,\n",
              " 0.23588614165782928,\n",
              " 0.2307022660970688,\n",
              " 0.2257208526134491,\n",
              " 0.220916748046875,\n",
              " 0.21627190709114075,\n",
              " 0.21176083385944366,\n",
              " 0.2074197232723236,\n",
              " 0.2032545804977417,\n",
              " 0.19924047589302063]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to(\"cuda:0\") \n",
        "y = y.to(\"cuda:0\") \n",
        "net.to(\"cuda:0\") "
      ],
      "metadata": {
        "id": "_-TPQDWEUQBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset과 dataloader \n",
        "# 파이토치에는 미니배치학습이나 데이터 셔플, 병렬처리까지 간단히 수행할수 있다\n",
        "# tensordataset은 Dataset을 상속한 클래스로 학습데이터 x 와 y를 묶어놓은 컨테이너\n",
        "# tensordataset을 dataloader에 전달하면 for루프에서 데이터의 일부만 간단히 추출할 수 있게 됨\n",
        "# tensordataset 에는 텐서만 전달가능, variable은 전달못함"
      ],
      "metadata": {
        "id": "s4FU7XitYF3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim \n",
        "from torch.utils.data import TensorDataset ,  DataLoader "
      ],
      "metadata": {
        "id": "3VBD6NQqe3wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 작성\n",
        "ds = TensorDataset(X,y) ; ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3qS_48Re-67",
        "outputId": "f700da99-2bcc-4f59-f20d-8c592fa28237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x7fd46a8bff10>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(ds, batch_size = 64, shuffle= True) \n",
        "loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcu3UIvJfDeY",
        "outputId": "88ff4943-29b7-4093-844c-27b4c33793e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd46a8bef90>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(64,32),\n",
        "    nn.ReLU(), \n",
        "    nn.Linear(32,16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16,10)\n",
        ")"
      ],
      "metadata": {
        "id": "VZihxco3fH7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss() \n",
        "optimizer = optim.Adam(net.parameters()) \n"
      ],
      "metadata": {
        "id": "1Y7A5y9sfcpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = [] \n",
        "for epoch in range(10): \n",
        "  running_loss= 0.0 \n",
        "  for xx,yy in loader: \n",
        "    y_pred=net(xx)  \n",
        "    loss = loss_fn(y_pred, yy)\n",
        "    optimizer.zero_grad() \n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "    running_loss += loss.item() \n",
        "  losses.append(running_loss) \n",
        "    #xx,yy 는 64개만 받음"
      ],
      "metadata": {
        "id": "FERrcuoIfiCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWgZbzyDf9RF",
        "outputId": "af928199-0dec-4ddc-f931-25bc7aabb7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[55.32143568992615,\n",
              " 34.529799461364746,\n",
              " 19.87132754921913,\n",
              " 12.466761708259583,\n",
              " 8.632823094725609,\n",
              " 6.737767234444618,\n",
              " 5.601164065301418,\n",
              " 4.7442793399095535,\n",
              " 4.217225477099419,\n",
              " 3.748868480324745]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset은 직접 작성할수도있어서 대량의 이미지 파일을 한번에 메모리에 저장하지않고, 필요할때마다 읽어서 학습하는 등 다양하게 활용가능"
      ],
      "metadata": {
        "id": "y0p8nLNWf-bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout을 활용한 정규화 \n",
        "import torch \n",
        "from torch import nn, optim \n",
        "from sklearn.model_selection import train_test_split \n",
        "X = digits.data \n",
        "Y = digits.target \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size= 0.3) "
      ],
      "metadata": {
        "id": "J50tVEtYgFo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype = torch.float32) \n",
        "Y_train = torch.tensor(Y_train, dtype = torch.int64) \n",
        "X_test = torch.tensor(X_test, dtype = torch.float32) \n",
        "Y_test = torch.tensor(Y_test, dtype = torch.int64) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBzFsFyAgj3d",
        "outputId": "a3f5851b-a99a-4493-dff0-630d7b79dc86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 100 # 여러층을 쌓아서 깊은 신경망 구축\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(64,k), \n",
        "    nn.ReLU(),\n",
        "    nn.Linear(k,k),\n",
        "    nn.ReLU(), \n",
        "    nn.Linear(k,k),\n",
        "    nn.ReLU(), \n",
        "    nn.Linear(k,k), \n",
        "    nn.ReLU(),\n",
        "    nn.Linear(k,10)\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "qINu45ZsjGMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss() \n",
        "optimizer= optim.Adam(net.parameters()) \n",
        "ds = TensorDataset(X_train, Y_train) \n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBdPgnNpjbGv",
        "outputId": "61750a76-4875-46c3-841b-8c3d1ad628ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x7fd46a903e10>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(ds, batch_size = 32, shuffle=True) ; loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnpMcoGljnCb",
        "outputId": "204349a7-4169-4660-c8d0-f0ed7fdd1769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd46a666fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "for epoch in range(100):\n",
        "  running_loss= 0.0\n",
        "  for i, (xx,yy) in enumerate(loader): \n",
        "    y_pred = net(xx) \n",
        "    loss = loss_fn(y_pred, yy) \n",
        "    optimizer.zero_grad() \n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "    running_loss += loss.item() \n",
        "  train_losses.append(running_loss / i) # i 로 나누는 이유?? 평균적인 loss를 보려고 하는것\n",
        "  y_pred = net(X_test)\n",
        "  test_loss = loss_fn(y_pred, Y_test)  \n",
        "  test_losses.append(test_loss.item()) \n"
      ],
      "metadata": {
        "id": "ucN8KgBuj2MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화\n",
        "# 과적합을 방지하는것\n",
        "k = 100 # 여러층을 쌓아서 깊은 신경망 구축\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(64,k), \n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(k,k),\n",
        "    nn.ReLU(), \n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(k,k),\n",
        "    nn.ReLU(), \n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(k,k), \n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(k,10)\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "3xunZ4aJk3QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "for epoch in range(100):\n",
        "  running_loss= 0.0\n",
        "  net.train() # t신경망을 훈련모드로 설정\n",
        "  for i, (xx,yy) in enumerate(loader): \n",
        "    y_pred = net(xx) \n",
        "    loss = loss_fn(y_pred, yy) \n",
        "    optimizer.zero_grad() \n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "    running_loss += loss.item() \n",
        "  train_losses.append(running_loss / i) # i 로 나누는 이유?? 평균적인 loss를 보려고 하는것\n",
        "  # 평가모드로설정\n",
        "  net.eval() # 검증데이터의 손실함수를 계산 \n",
        "  y_pred = net(X_test)\n",
        "  test_loss = loss_fn(y_pred, Y_test)  \n",
        "  test_losses.append(test_loss.item()) \n"
      ],
      "metadata": {
        "id": "kGEqIbwLu1MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU36Jbpgu2qs",
        "outputId": "e78193e8-36ec-4465-94be-4222be8ddcd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3610274302653775,\n",
              " 2.2043962692603087,\n",
              " 1.956600091396234,\n",
              " 1.65519157739786,\n",
              " 1.3902300321138823,\n",
              " 1.1843211956513233,\n",
              " 1.0467613232441437,\n",
              " 0.8775177215918516,\n",
              " 0.8105171720186869,\n",
              " 0.7399123097077395,\n",
              " 0.6882622417731162,\n",
              " 0.6238639996601985,\n",
              " 0.528213976476437,\n",
              " 0.50357958731743,\n",
              " 0.4658267184709891,\n",
              " 0.42917864674176925,\n",
              " 0.40252442027513796,\n",
              " 0.4420751474606685,\n",
              " 0.35107189665238064,\n",
              " 0.3504583415312645,\n",
              " 0.3709388512831468,\n",
              " 0.3876523595207777,\n",
              " 0.3290632817034538,\n",
              " 0.29801373498944134,\n",
              " 0.2386190939026001,\n",
              " 0.31124694645404816,\n",
              " 0.28893481538845944,\n",
              " 0.2808188647031784,\n",
              " 0.27931661053727835,\n",
              " 0.26494748966816145,\n",
              " 0.25454682532029277,\n",
              " 0.24746310090025267,\n",
              " 0.2289918346855885,\n",
              " 0.22976089904132563,\n",
              " 0.21758992989093828,\n",
              " 0.19599501110422304,\n",
              " 0.1909723873130786,\n",
              " 0.20587997157604265,\n",
              " 0.19110043490162262,\n",
              " 0.2053485312140905,\n",
              " 0.18415649717625898,\n",
              " 0.2570296027100621,\n",
              " 0.16047002451542097,\n",
              " 0.2007739733044918,\n",
              " 0.16123607377402294,\n",
              " 0.17833269879412958,\n",
              " 0.1606591927508513,\n",
              " 0.16347435522729006,\n",
              " 0.1366727043611881,\n",
              " 0.20891015413097846,\n",
              " 0.16470371129421088,\n",
              " 0.1597641066003304,\n",
              " 0.13753718849367055,\n",
              " 0.14523186682699582,\n",
              " 0.19643018970218223,\n",
              " 0.13089589541777968,\n",
              " 0.13967080829808345,\n",
              " 0.15342914838439378,\n",
              " 0.10525436505961877,\n",
              " 0.14723392812391886,\n",
              " 0.09963429682195568,\n",
              " 0.11330719461712317,\n",
              " 0.1823887287471921,\n",
              " 0.19071884905823913,\n",
              " 0.17857412413622326,\n",
              " 0.13316352321551397,\n",
              " 0.13849137170622364,\n",
              " 0.10993080442317595,\n",
              " 0.13290177715512422,\n",
              " 0.1319184355581036,\n",
              " 0.12976362109661865,\n",
              " 0.10823966381259453,\n",
              " 0.13998576590361503,\n",
              " 0.14543826266741142,\n",
              " 0.11849969681591177,\n",
              " 0.10514922683628705,\n",
              " 0.14089477807432652,\n",
              " 0.15976756822485,\n",
              " 0.12596215367953753,\n",
              " 0.11892261045674483,\n",
              " 0.15400878028371012,\n",
              " 0.1296799331306456,\n",
              " 0.10366631902527446,\n",
              " 0.11627165629313542,\n",
              " 0.13098667069481543,\n",
              " 0.14114510927585144,\n",
              " 0.11767817866534759,\n",
              " 0.11207290953741623,\n",
              " 0.08978608287632084,\n",
              " 0.0795994219608987,\n",
              " 0.1531672601092559,\n",
              " 0.10832007546933034,\n",
              " 0.14629428246870446,\n",
              " 0.12314787636009547,\n",
              " 0.16317936634788147,\n",
              " 0.12012558428045267,\n",
              " 0.10525748134853366,\n",
              " 0.0932780783265256,\n",
              " 0.10921677482577088,\n",
              " 0.0920002600357223]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7y2d-A5u9qh",
        "outputId": "6e585401-7dad-4752-eb6c-5f7f94b42f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.2026541233062744,\n",
              " 1.9123437404632568,\n",
              " 1.4365808963775635,\n",
              " 1.1535295248031616,\n",
              " 0.8362278342247009,\n",
              " 0.6825329661369324,\n",
              " 0.5394718050956726,\n",
              " 0.3833886981010437,\n",
              " 0.34048470854759216,\n",
              " 0.29444438219070435,\n",
              " 0.24658480286598206,\n",
              " 0.21916034817695618,\n",
              " 0.17136529088020325,\n",
              " 0.18368731439113617,\n",
              " 0.16931898891925812,\n",
              " 0.16070421040058136,\n",
              " 0.14695248007774353,\n",
              " 0.13920700550079346,\n",
              " 0.12448720633983612,\n",
              " 0.12774644792079926,\n",
              " 0.14139099419116974,\n",
              " 0.12399831414222717,\n",
              " 0.12294887751340866,\n",
              " 0.1487322300672531,\n",
              " 0.10081972926855087,\n",
              " 0.09674730151891708,\n",
              " 0.13279153406620026,\n",
              " 0.12911356985569,\n",
              " 0.11591397225856781,\n",
              " 0.10609907656908035,\n",
              " 0.09140941500663757,\n",
              " 0.10544311255216599,\n",
              " 0.09819336235523224,\n",
              " 0.09699522703886032,\n",
              " 0.10246051847934723,\n",
              " 0.1325278878211975,\n",
              " 0.09323547780513763,\n",
              " 0.10215133428573608,\n",
              " 0.11906658113002777,\n",
              " 0.10569645464420319,\n",
              " 0.10109468549489975,\n",
              " 0.08723022788763046,\n",
              " 0.09026185423135757,\n",
              " 0.08049970865249634,\n",
              " 0.11460939049720764,\n",
              " 0.08095239102840424,\n",
              " 0.10756871104240417,\n",
              " 0.11983033269643784,\n",
              " 0.0991259217262268,\n",
              " 0.07898823916912079,\n",
              " 0.06778071820735931,\n",
              " 0.09976708143949509,\n",
              " 0.07663678377866745,\n",
              " 0.09885682165622711,\n",
              " 0.13163365423679352,\n",
              " 0.08779869973659515,\n",
              " 0.10722275823354721,\n",
              " 0.10359624028205872,\n",
              " 0.09460961073637009,\n",
              " 0.11952565610408783,\n",
              " 0.0929412767291069,\n",
              " 0.14710365235805511,\n",
              " 0.10003791004419327,\n",
              " 0.131374791264534,\n",
              " 0.10653870552778244,\n",
              " 0.07986384630203247,\n",
              " 0.06199751794338226,\n",
              " 0.0631520003080368,\n",
              " 0.07602453976869583,\n",
              " 0.06674692779779434,\n",
              " 0.08607321232557297,\n",
              " 0.09314198046922684,\n",
              " 0.10697473585605621,\n",
              " 0.0769205167889595,\n",
              " 0.0828905925154686,\n",
              " 0.05973644182085991,\n",
              " 0.1492644101381302,\n",
              " 0.07510299980640411,\n",
              " 0.053957246243953705,\n",
              " 0.07551011443138123,\n",
              " 0.09041544795036316,\n",
              " 0.10522095859050751,\n",
              " 0.09123754501342773,\n",
              " 0.09990746527910233,\n",
              " 0.1296023577451706,\n",
              " 0.11201145499944687,\n",
              " 0.09129558503627777,\n",
              " 0.0769755095243454,\n",
              " 0.10185937583446503,\n",
              " 0.11562658101320267,\n",
              " 0.1294240951538086,\n",
              " 0.13063763082027435,\n",
              " 0.15120959281921387,\n",
              " 0.06800325214862823,\n",
              " 0.07954660803079605,\n",
              " 0.09118881076574326,\n",
              " 0.0939948558807373,\n",
              " 0.11085689812898636,\n",
              " 0.0671248510479927,\n",
              " 0.0954192727804184]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch normalization을 사용한 학습 가속\n",
        "# sgd를 사용한 신경망 학습에서는 각 변수의 차원이 동일한 범위의 값을 가지는것이 중요\n",
        "# 한 층으로 된 선형모델 등에서는 사전에 데이터를 정규화해 두면 되지만 깊은 신경망에서는 층이 늘어날수록 데이터 분포가 바뀜\n",
        "# 따라서 인력 데이터의 정규화만으로는 부족함\n",
        "# 앞의 있는 층의 학습에 의해 파라미터가 변하므로 뒤에 있는 층의 학습이 불안정해지는 문제가 있다\n",
        "# 안정화 및 가속화 하는 방법 : batch n  ormalization / 훈련시에만 적용됨, 평가시에는 사용안함\n",
        "# dropout과 동일하게 train 과 eval메서드로 모드를 적용하거나 미적용 할수 있음"
      ],
      "metadata": {
        "id": "riILNvW8vsEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화\n",
        "# 과적합을 방지하는것\n",
        "k = 100 # 여러층을 쌓아서 깊은 신경망 구축\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(64,k), \n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.BatchNorm1d(k),\n",
        "    nn.Linear(k,k),\n",
        "    nn.ReLU(), \n",
        "    nn.Dropout(0.5),\n",
        "    nn.BatchNorm1d(k),\n",
        "    nn.Linear(k,k),\n",
        "    nn.ReLU(), \n",
        "    nn.Dropout(0.5),\n",
        "    nn.BatchNorm1d(k),\n",
        "    nn.Linear(k,k), \n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(k,10)\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "H4hXI5wv3YrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망의 모듈화\n",
        "# 직접 신경망 계층을 정의할 수 있음\n",
        "# 자체 클래스를 만들 수 있는 것처럼 자체 신경망 계층을 만들어서 재사용하거나 이것을 부품으로 이용해서 더 복잡한 신경망을 만들 수 있음\n",
        "# 자체 신경망 계층을 만들려면 nn.Module을 상속해서 클래스를 정의\n",
        "# nn.Module은 nn.Linear를 포함한 모든계층의 기반 클래스다\n",
        "# 커스텀 계층을 만들때에 forward메서드를 구현하면 자동 미분까지 가능해짐\n",
        "# nn.Module은 __call__ 메서드는 내부에서 forward메서드를 사용하고 있음\n"
      ],
      "metadata": {
        "id": "7p4I8T683fTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear(nn.Module): \n",
        "  def __init__(self, in_features, out_features, bias=True, p=0.5):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(in_features, out_features, bias) \n",
        "    self.relu = nn.ReLU() \n",
        "    self.drop = nn.Dropout(p) \n",
        "  def forward(self,x): \n",
        "    x=self.linear(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.drop(x)\n",
        "    return x\n",
        "\n",
        "mlp = nn.Sequential(\n",
        "    CustomLinear(64,200),\n",
        "    CustomLinear(64,200),\n",
        "    CustomLinear(200,200),\n",
        "    nn.Linear(200,10)\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "nUP8oWas6-oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMLP(nn.Module): \n",
        "  def __init__(self, in_features, out_features): \n",
        "    super().__init__() \n",
        "    self.ln1 = CustomLinear(in_features, 200)\n",
        "    self.ln2 = CustomLinear(200, 200)\n",
        "    self.ln3 = CustomLinear(200, 200)\n",
        "    self.ln4 = CustomLinear(200, out_features)\n",
        "  def forward(self,x):\n",
        "    x=self.ln1(x)\n",
        "    x=self.ln2(x)\n",
        "    x=self.ln3(x)\n",
        "    x=self.ln4(x)\n",
        "    return x\n",
        "\n",
        "mlp = MyMLP(64,10) "
      ],
      "metadata": {
        "id": "ajbf2KwI7jN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irM2nTPa8M22",
        "outputId": "9f5e3990-b8bc-4d4b-d2a1-6302c7a9b12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyMLP(\n",
              "  (ln1): CustomLinear(\n",
              "    (linear): Linear(in_features=64, out_features=200, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (drop): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (ln2): CustomLinear(\n",
              "    (linear): Linear(in_features=200, out_features=200, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (drop): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (ln3): CustomLinear(\n",
              "    (linear): Linear(in_features=200, out_features=200, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (drop): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (ln4): CustomLinear(\n",
              "    (linear): Linear(in_features=200, out_features=10, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (drop): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IfStLyzB8RSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.이미지처리와 합성곱 신경망"
      ],
      "metadata": {
        "id": "cVajl_7Y8Ysm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bQ22_H0k8mlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rhkx05K08mpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lzv0b_8n8mr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p4OMUP6o8mud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.자연어처리와 순환신경망 "
      ],
      "metadata": {
        "id": "BTN4ubEA8aOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN: 일반적인 신경망과 다른점은 내부상태를 저장하고 있다는점\n",
        "# 일반신경망보다 훈련이 어려움\n",
        "# 오랜시간동안 쌓인 이력을 사용하려고 하면 그만큼 깊은 신경망이 되어야하며, 경사손실이나 경사분실등의 문제가 발생\n",
        "# 이를 해결하기 위해 단순한 선형계층이 아닌 더 정교한 처리를 모아 모듈 블록을 바꾼 LSTM, GRU등의 RNN도 있음\n"
      ],
      "metadata": {
        "id": "eQz9YLBF8kGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트 데이터의 수치화\n",
        "# 정규화와 토큰화\n",
        "# ISN'T -> IS NOT \n"
      ],
      "metadata": {
        "id": "u8Rn-gdQA7ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전구축 \n",
        "# 토큰을 수집하고 거기에 ID를 부여하는 작업\n",
        "#등장 순서대로 부여해도되고 빈도순으로 해도됨\n"
      ],
      "metadata": {
        "id": "ZBE1N4AyBCsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치로 변환\n",
        "# 토큰의 리스트로 분할된 문장을 ID리스트로 전환"
      ],
      "metadata": {
        "id": "Lox_HI6iBKgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn \n",
        "# I YOU AM OF (1,0,1,3...)\n",
        "# BOW : 계산이 간단하고, 여러문장을 모으면 희소행렬로 표현할 수 있어서 매우 효율이 좋지만 토큰순서라는 중요한 정보를 잃음\n",
        "# 파이토치에서는 nn.embedding을 사용해서 embedding계층을 만들 수 있음\n",
        "emb = nn.Embedding(10000, 20, padding_idx=0)  # 사전에 없는 토큰은 모두 0으로 처리하고 실제 id는 1부터 시작하도록 사용하면 좋음\n",
        "#nn.embedding도 미분가능하므로 이 내부의 가중치 파라미터도 신경망 전체 훈련시에 최적화할수 있으며, 사전에 학습된 nn.embedding을 이용해서 다른문제를 해결할 수 있음\n",
        "# 입력은 int64텐서\n",
        "inp = torch.tensor([1,2,5,2,10], dtype=torch.int64)\n",
        "out = emb(inp); out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jweYLHNBP-p",
        "outputId": "389c9062-6080-4fe5-fb65-c5e04212b903"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.8630e-01, -1.4886e+00,  2.0535e-01, -7.5953e-01,  2.0989e-01,\n",
              "          6.2100e-01, -8.5864e-01, -1.7350e+00, -3.1527e-01, -1.7605e+00,\n",
              "          1.7930e-01, -1.4128e+00, -4.9873e-01,  4.7768e-01, -6.3432e-01,\n",
              "          1.0482e+00,  1.7583e+00,  1.8462e+00,  8.2710e-04,  4.8238e-02],\n",
              "        [-3.4659e-02, -9.0258e-01,  4.7048e-01, -5.9875e-01,  8.3581e-01,\n",
              "         -1.6704e-01, -6.7518e-01,  3.5825e-02, -1.7965e+00,  1.2581e+00,\n",
              "          2.0829e-01,  1.7496e+00, -1.7497e-01, -1.7032e+00, -1.0793e+00,\n",
              "          9.2888e-01,  6.4488e-01,  5.9015e-02,  2.2137e-01,  9.3084e-02],\n",
              "        [-1.6319e+00,  1.0066e+00, -1.4149e-01, -1.4196e+00,  4.8267e-01,\n",
              "          3.3317e-01, -2.7442e-01, -2.7664e-02,  2.6116e-01, -9.7496e-01,\n",
              "          1.2887e+00, -1.2396e+00, -8.6667e-01,  8.5531e-01, -1.7068e+00,\n",
              "         -9.6811e-01, -5.5781e-01, -5.6660e-01,  9.7823e-02, -1.7014e+00],\n",
              "        [-3.4659e-02, -9.0258e-01,  4.7048e-01, -5.9875e-01,  8.3581e-01,\n",
              "         -1.6704e-01, -6.7518e-01,  3.5825e-02, -1.7965e+00,  1.2581e+00,\n",
              "          2.0829e-01,  1.7496e+00, -1.7497e-01, -1.7032e+00, -1.0793e+00,\n",
              "          9.2888e-01,  6.4488e-01,  5.9015e-02,  2.2137e-01,  9.3084e-02],\n",
              "        [-3.4103e-01,  2.0136e-01,  1.0161e+00, -1.6331e-01, -4.8222e-01,\n",
              "         -3.0321e-01,  8.0904e-01,  2.1147e-01,  9.6702e-01,  2.1611e-01,\n",
              "         -3.4976e-01,  1.6454e+00,  5.6703e-01, -1.0672e-01,  7.9461e-01,\n",
              "         -1.1607e-02, -5.6206e-01, -6.7623e-01, -1.5042e+00, -4.9832e-01]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN과 문장분류\n",
        "# IMDB데이터 (아마존 운영)\n",
        "# 계열 레이블링"
      ],
      "metadata": {
        "id": "vDMO_PTTCf03"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz # 압축파일 다운로드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL19TqOFCpHJ",
        "outputId": "63ef792b-f851-4813-fc37-61a7f9c336a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 03:25:14--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  15.4MB/s    in 13s     \n",
            "\n",
            "2022-06-27 03:25:28 (6.28 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf aclImdb_v1.tar.gz # 파일 압축 풀기"
      ],
      "metadata": {
        "id": "-BnmXgnWBvtE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pathlib\n",
        "import re   \n",
        "remove_marks_regex = re.compile(\"[,\\.\\(\\)\\[\\]\\*;:]<.*?>\") # 자주쓰는 정규표현식을 저장하고 싶을 땐 compile() 메서드를 사용\n",
        "shift_marks_regex = re.compile(\"([?!])\")"
      ],
      "metadata": {
        "id": "eJwaYaTqDIAI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 긴 문자열을 토큰 id리스트로 변환하는 함수\n",
        "# 정규표현을 사용해서 문장 부호나 괄호를 제거하고, !나 ?단어사이에 공백을 넣어서 단어와 별도로 토큰으로 분할\n",
        "# imdb.vocab에 두 기호가 포함됨\n",
        "# 용어집에 포함되지 않은 토큰은 0 할당\n",
        "def text2ids(text, vocab_dict): \n",
        "  # !?이외의 기호삭제\n",
        "  text = remove_marks_regex.sub(\"\",text) \n",
        "  # !?와 단어사이에 공백삽입\n",
        "  text = shift_marks_regex.sub(r\" \\1\", text) \n",
        "  tokens= text.split() \n",
        "  return [vocab_dict.get(token,0) for token in tokens] "
      ],
      "metadata": {
        "id": "J_UQ6AOKVJ58"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# id리스트를 int64의 텐서로 변환하는 함수, \n",
        "# 변환할때는 각 문장을 분할한후 토큰수를 제한하고, 반대로 그 수에 미치지 못하는 경우에는 뒤를 0d로 채움\n",
        "\n",
        "def list2tensor(token_idxes, max_len = 100, padding=True): \n",
        "  if len(token_idxes) > max_len: \n",
        "    token_idxes = token_idxes[:max_len] \n",
        "  n_tokens = len(token_idxes) \n",
        "  if padding:\n",
        "    token_idxes = token_idxes + [0] * (max_len - len(token_idxes)) \n",
        "  return torch.tensor(token_idxes, dtype=torch.int64), n_tokens "
      ],
      "metadata": {
        "id": "MtlOLj0pV-V_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 클래스 작성\n",
        "# 생성자 내에서 텍스트 파일의 경로와 레이블을 모은 튜플 리스트를 만들기\n",
        "# __getitem__ 내에서 이파일을 읽어서 텐서로 변환"
      ],
      "metadata": {
        "id": "HaJ6x64Ve24G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim \n",
        "import tqdm\n",
        "from torch.utils.data import (Dataset, DataLoader, TensorDataset) "
      ],
      "metadata": {
        "id": "FDEiIkvifHG-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset(Dataset): \n",
        "  def __init__(self, dir_path, train=True, max_len = 100, padding=True): \n",
        "    self.max_len = max_len \n",
        "    self.padding = padding \n",
        "    path = pathlib.Path(dir_path) \n",
        "    vocab_path = path.joinpath(\"imdb.vocab\") \n",
        "    # 용어집 파일을 읽어 행단위로 분할\n",
        "    self.vocab_array = vocab_path.open().read().strip().splitlines() \n",
        "    # 단어가 키이고 값이 id인 dict만들기\n",
        "    self.vocab_dict = dict((w, i+1) for (i,w) in enumerate(self.vocab_array)) \n",
        "    if train : \n",
        "      target_path = path.joinpath(\"train\")\n",
        "    else: \n",
        "      target_path = path.joinpath(\"test\") \n",
        "    pos_files = sorted(glob.glob(str(target_path.joinpath(\"pos/*.txt\")))) # glob는 dir같은 역할\n",
        "    neg_files = sorted(glob.glob(str(target_path.joinpath(\"neg/*.txt\"))))\n",
        "    self.labeled_files = list(zip([0]*len(neg_files), neg_files)) + list(zip([1]*len(pos_files), pos_files))\n",
        "\n",
        "  @property\n",
        "  def vocab_size(self): \n",
        "    return len(self.vocab_array) \n",
        "  \n",
        "  def __len__(self): \n",
        "    return len(self.labeled_files) \n",
        "  \n",
        "  def __getitem__(self,idx): \n",
        "    label, f= self.labeled_files[idx]  \n",
        "    #파일의 텍스트 데이터를 읽어서 소문자로 변환\n",
        "    data =open(f).read().lower() \n",
        "    data = text2ids(data, self.vocab_dict) \n",
        "    data, n_tokens = list2tensor(data, self.max_len, self.padding) \n",
        "    return data, label, n_tokens \n",
        "  "
      ],
      "metadata": {
        "id": "YtbaKTRQfgdp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련용과 테스트용 dataloader\n",
        "train_data = IMDBDataset(\"/content/aclImdb/\") \n",
        "test_data = IMDBDataset(\"/content/aclImdb/\", train=False)"
      ],
      "metadata": {
        "id": "lf548pjOesb8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTQ5h1YL7iKK",
        "outputId": "792fbfb6-1cba-4b0d-cb81-224cfe79b754"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89527"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHivUg41H5bu",
        "outputId": "b7e7ce1c-52c5-4b59-fcfa-d6e4aab058ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.IMDBDataset at 0x7f0711b395d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLJm4wKe8Gtw",
        "outputId": "d710439f-041b-4102-ae43-7762c5bda903"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#신경망 정의와 훈련\n",
        "# 특정 정수의 시계열 x가 입력됐을때에 0또는1 출력되는 2진분류\n",
        "# \n",
        "class SequenceTaggingNet(nn.Module): \n",
        "  def __init__(self, num_embeddings, embedding_dim=50, hidden_size=50, num_layers=1, dropout=0.2):\n",
        "    super().__init__()  \n",
        "    self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx= 0) \n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout) \n",
        "    self.linear = nn.Linear(hidden_size, 1) \n",
        "  def forward(self, x, h0=None, l = None): \n",
        "    # ID를 EMBEDDING으로 다차원 벡터로 변환\n",
        "    # x : (batch_size, step_size) \n",
        "    # -> (batch_size, step_size, embedding_size) \n",
        "    x= self.emb(x) \n",
        "    # 초기상태 h0와 함께 rnn에 x 전달\n",
        "    # x : (batch_size, step_size, embedding_dim)\n",
        "    # -> (batch_size, step_size, hidden_dim)\n",
        "    \n",
        "    x,h = self.lstm(x,h0) \n",
        "    # 마지막단계만 추출\n",
        "    # x : (batch_size, step_size, hidden_dim) \n",
        "    # -> (batch_size, 1)\n",
        "\n",
        "    # 입력의 원래길이가 있으면 그것을 이용\n",
        "    if l is not None: \n",
        "      x = x[list(range(len(x))), l-1, :] \n",
        "    \n",
        "    # 없음면 단순히 마지막 것을 이용\n",
        "    else: \n",
        "      x = x[:,-1,:] \n",
        "    \n",
        "    # 마지막 단계를 선형계층에 넣음\n",
        "    x = self.linear(x) \n",
        "    # 불필요한 차원을 삭제\n",
        "    # (batch_size, 1) -> (batch_size, )\n",
        "    x = x.squeeze() \n",
        "    return x "
      ],
      "metadata": {
        "id": "UL5Hd89f8Pyt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치의 rnn계열 : nn.LSTM, nn.GRU, nn.RNN\n",
        "# 파이토치의 RNN계열은 입력차원, 충간층의 차원외에도 계층수, BATCH_FIRST, DROPOUT등의 인수지정 가능\n",
        "# RNN계열은 RNN을 여러계층으로 연결가능 (num_layers로 설정)\n",
        "# rnn계열의 입출력차원 : (단계수, 배치수, 특이수)\n",
        "# batch_first= true지정시 : (배치수, 단계수, 특이수) / 다른 신경망층에서는 반드시 첫번째 차원이 배치수이므로 이게 유용함\n",
        "# None : 모든값이 0인 벡터를 입력한것과 같음\n"
      ],
      "metadata": {
        "id": "vlWZwC-C-Fnw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 및 평가 작성\n",
        "def eval_net(net, data_loader, device= \"cpu\"):\n",
        "  net.eval() \n",
        "  ys = []\n",
        "  y_preds=[]\n",
        "  for x,y,l in data_loader:\n",
        "    x = x.to(device) \n",
        "    y = y.to(device) \n",
        "    l= l.to(device) \n",
        "    with torch.no_grad():\n",
        "      y_pred = net(x, l=l) \n",
        "      y_pred = (y_pred>0).long()\n",
        "      ys.append(y) \n",
        "      y_preds.append(y_pred)\n",
        "\n",
        "  ys = torch.cat(ys)\n",
        "  y_preds = torch.cat(y_preds) \n",
        "  acc = (ys==y_preds).float().sum() / len(ys) \n",
        "  return acc.item()  "
      ],
      "metadata": {
        "id": "1odnHOtlEkIo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Q-lYGPHfkw",
        "outputId": "61c5debf-669c-448b-f041-72409272b08c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.IMDBDataset at 0x7f0711b395d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean \n",
        "net = SequenceTaggingNet(train_data.vocab_size+1, num_layers=2) \n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96zZBKnKG2IA",
        "outputId": "99400240-8124-40be-8f4a-7bdc9ec1a533"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceTaggingNet(\n",
              "  (emb): Embedding(89528, 50, padding_idx=0)\n",
              "  (lstm): LSTM(50, 50, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#net.to(\"cuda:0\") "
      ],
      "metadata": {
        "id": "iRYSDlMvHoTq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(net.parameters()) \n",
        "loss_f = nn.BCEWithLogitsLoss() "
      ],
      "metadata": {
        "id": "oEuzRQNXKSpW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10): \n",
        "  losses = []\n",
        "  net.train() \n",
        "  for x,y,l in tqdm.tqdm(train_loader): \n",
        "    #x = x.to(\"cuda:0\")\n",
        "    #y = y.to(\"cuda:0\")\n",
        "    #l = l.to(\"cuda:0\")\n",
        "    y_pred = net(x, l=l) \n",
        "    loss = loss_f(y_pred, y.float()) \n",
        "    net.zero_grad() \n",
        "    loss.backward() \n",
        "    opt.step() \n",
        "    losses.append(loss.item()) \n",
        "  train_acc = eval_net(net, train_loader)\n",
        "  val_acc = eval_net(net, test_loader )\n",
        "  print(epoch, mean(losses), train_acc, val_acc)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzIRK8osLl9f",
        "outputId": "3f744035-182a-40e4-bb36-9920dc97ceb0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/782 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 782/782 [01:44<00:00,  7.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.4292671939982173 0.8601599931716919 0.7707200050354004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:45<00:00,  7.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.36117874674708644 0.8960400223731995 0.7813599705696106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:45<00:00,  7.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 0.28058733386190043 0.9264000058174133 0.7830399870872498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:47<00:00,  7.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 0.22604908776062224 0.948639988899231 0.7850000262260437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:46<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 0.1764431312880324 0.967519998550415 0.7763599753379822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:47<00:00,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 0.13742972972095394 0.9698399901390076 0.7660800218582153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:45<00:00,  7.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 0.102312739360887 0.9834799766540527 0.7672399878501892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:47<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 0.08278536191984268 0.9877200126647949 0.7660800218582153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:46<00:00,  7.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 0.06632936650189235 0.9917200207710266 0.7652000188827515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:47<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 0.0513252585428431 0.986519992351532 0.7590399980545044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rnn을 사용하지않는 모델작성\n"
      ],
      "metadata": {
        "id": "gDemmHeVMe6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}